# ğŸ¯ Ù†Ø¸Ø§Ù… Embeddings Ù„Ù„Ù†ØµÙˆØµ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© - Ø¯Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„

## ğŸ“‹ Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø©

Ù†Ø¸Ø§Ù… Ù…ØªÙƒØ§Ù…Ù„ Ù„ØªÙˆÙ„ÙŠØ¯ ÙˆØ¥Ø¯Ø§Ø±Ø© embeddings Ù„Ù„Ù†ØµÙˆØµ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… **sentence-transformers**. ÙŠØ¯Ø¹Ù… Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ Ø§Ù„Ø°ÙƒÙŠ ÙˆÙŠÙˆÙØ± API ÙƒØ§Ù…Ù„ Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù€ embeddings.

### âœ¨ Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©

âœ… **Ø¯Ø¹Ù… Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©**: Ù†Ù…Ø§Ø°Ø¬ Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ù„ØºØ§Øª Ù…ÙØ­Ø³ÙÙ‘Ù†Ø© Ù„Ù„Ø¹Ø±Ø¨ÙŠØ©  
âœ… **Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¬Ù…Ø§Ø¹ÙŠØ©**: Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¢Ù„Ø§Ù Ø§Ù„Ù€ chunks Ø¨ÙƒÙØ§Ø¡Ø© Ø¹Ø§Ù„ÙŠØ©  
âœ… **Ø¨Ø­Ø« Ø¯Ù„Ø§Ù„ÙŠ**: Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ù€ chunks Ø§Ù„Ø£ÙƒØ«Ø± ØªØ´Ø§Ø¨Ù‡Ø§Ù‹ Ø¯Ù„Ø§Ù„ÙŠØ§Ù‹  
âœ… **API ÙƒØ§Ù…Ù„**: endpoints Ù„ØªÙˆÙ„ÙŠØ¯ ÙˆØ§Ø³ØªØ±Ø¬Ø§Ø¹ ÙˆØ§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù€ embeddings  
âœ… **Ø³ÙƒØ±ÙŠØ¨Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¬Ù…Ø§Ø¹ÙŠØ©**: Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ© Ø¨Ø³Ù‡ÙˆÙ„Ø©  
âœ… **Ù…Ø±ÙˆÙ†Ø© Ø¹Ø§Ù„ÙŠØ©**: Ø¯Ø¹Ù… Ù†Ù…Ø§Ø°Ø¬ Ù…ØªØ¹Ø¯Ø¯Ø© (default, large, small)  
âœ… **ÙƒØ§Ø´ÙŠÙ†Øº Ø°ÙƒÙŠ**: ØªØ®Ø²ÙŠÙ† Ù…Ø¤Ù‚Øª Ù„Ù„Ù€ embeddings Ø§Ù„Ù…ØªÙƒØ±Ø±Ø©  

---

## ğŸ—ï¸ Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù†Ø¸Ø§Ù…

```
app/
â”œâ”€â”€ services/
â”‚   â””â”€â”€ embedding_service.py         # Ø®Ø¯Ù…Ø© ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù€ embeddings
â”‚
â”œâ”€â”€ routes/
â”‚   â””â”€â”€ embedding_router.py          # API endpoints
â”‚
â”œâ”€â”€ schemas/
â”‚   â””â”€â”€ embedding.py                 # Pydantic schemas
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ legal_knowledge.py           # KnowledgeChunk model (updated)
â”‚
scripts/
â””â”€â”€ generate_embeddings_batch.py     # Ø³ÙƒØ±ÙŠØ¨Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¬Ù…Ø§Ø¹ÙŠØ©

alembic/
â””â”€â”€ versions/
    â””â”€â”€ add_embedding_vector_to_knowledge_chunks.py  # Migration
```

---

## ğŸ”§ Ø§Ù„ØªØ«Ø¨ÙŠØª ÙˆØ§Ù„Ø¥Ø¹Ø¯Ø§Ø¯

### 1. Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©

Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ù…ÙˆØ¬ÙˆØ¯Ø© Ø¨Ø§Ù„ÙØ¹Ù„ ÙÙŠ `requirements.txt`:

```txt
sentence-transformers>=2.2.0
numpy>=1.24.0
faiss-cpu>=1.7.0
torch>=2.0.0
```

### 2. ØªØ´ØºÙŠÙ„ Migration

```bash
# ØªÙ†ÙÙŠØ° migration Ù„Ø¥Ø¶Ø§ÙØ© Ø­Ù‚Ù„ embedding_vector
alembic upgrade head
```

Ù‡Ø°Ø§ Ø³ÙŠØ¶ÙŠÙ Ø­Ù‚Ù„ `embedding_vector` Ù…Ù† Ù†ÙˆØ¹ JSON Ø¥Ù„Ù‰ Ø¬Ø¯ÙˆÙ„ `knowledge_chunks`.

### 3. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªØ«Ø¨ÙŠØª

```python
# Ø§Ø®ØªØ¨Ø§Ø± Ø³Ø±ÙŠØ¹
from app.services.embedding_service import EmbeddingService
from app.db.database import get_db_session

async with get_db_session() as db:
    service = EmbeddingService(db)
    service.initialize_model()
    print("âœ… Embedding service initialized successfully!")
```

---

## ğŸ“Š Database Schema

### KnowledgeChunk Model (Ù…Ø­Ø¯ÙÙ‘Ø«)

```python
class KnowledgeChunk(Base):
    __tablename__ = "knowledge_chunks"
    
    id = Column(Integer, primary_key=True, index=True)
    document_id = Column(Integer, ForeignKey("knowledge_documents.id"), nullable=False)
    chunk_index = Column(Integer, nullable=False)
    content = Column(Text, nullable=False)
    tokens_count = Column(Integer)
    
    # Legacy embedding field (for backward compatibility)
    embedding = Column(Text)
    
    # âœ¨ NEW: Vector embeddings from sentence-transformers
    embedding_vector = Column(JSON)  # Stores list of floats as JSON
    
    verified_by_admin = Column(Boolean, default=False)
    
    # Foreign keys
    law_source_id = Column(Integer, ForeignKey("law_sources.id"))
    case_id = Column(Integer, ForeignKey("legal_cases.id"))
    article_id = Column(Integer, ForeignKey("law_articles.id"))
    
    created_at = Column(DateTime, server_default=func.now())
```

**Ø­Ù‚Ù„ `embedding_vector`**:
- Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: `JSON`
- ÙŠØ®Ø²Ù† Ù‚Ø§Ø¦Ù…Ø© Ù…Ù† Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ø¹Ø´Ø±ÙŠØ© (embedding vector)
- Ù…Ø«Ø§Ù„: `[0.123, -0.456, 0.789, ...]` (768 dimensions for default model)

---

## ğŸ¯ EmbeddingService - Ø§Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©

### Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª

```python
class EmbeddingService:
    """Ø®Ø¯Ù…Ø© Ù…ØªÙƒØ§Ù…Ù„Ø© Ù„ØªÙˆÙ„ÙŠØ¯ ÙˆØ¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù€ embeddings"""
    
    # 1. ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    def initialize_model(self):
        """ÙŠØ­Ù…Ù‘Ù„ Ù†Ù…ÙˆØ°Ø¬ sentence-transformers"""
    
    # 2. ØªÙˆÙ„ÙŠØ¯ embeddings
    async def generate_chunk_embedding(chunk):
        """ÙŠÙˆÙ„Ø¯ embedding Ù„Ù€ chunk ÙˆØ§Ø­Ø¯"""
    
    async def generate_document_embeddings(document_id):
        """ÙŠÙˆÙ„Ø¯ embeddings Ù„ÙƒÙ„ chunks ÙÙŠ document"""
    
    async def generate_batch_embeddings(chunk_ids):
        """ÙŠÙˆÙ„Ø¯ embeddings Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© chunks"""
    
    # 3. Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ
    async def find_similar_chunks(query, top_k=10, threshold=0.7):
        """ÙŠØ¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù€ chunks Ø§Ù„Ø£ÙƒØ«Ø± ØªØ´Ø§Ø¨Ù‡Ø§Ù‹"""
    
    # 4. Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡
    def calculate_similarity(embedding1, embedding2):
        """ÙŠØ­Ø³Ø¨ cosine similarity Ø¨ÙŠÙ† embeddingÙŠÙ†"""
    
    # 5. Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…
    async def get_embedding_status(document_id):
        """ÙŠØ¹Ø±Ø¶ Ø­Ø§Ù„Ø© embeddings Ù„Ù€ document"""
    
    async def get_global_embedding_status():
        """ÙŠØ¹Ø±Ø¶ Ø­Ø§Ù„Ø© embeddings Ù„ÙƒÙ„ Ø§Ù„Ù†Ø¸Ø§Ù…"""
```

### Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©

```python
MODELS = {
    'default': 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2',
        # âœ… Ù…ØªÙˆØ§Ø²Ù† (768 dim) - Ø§Ù„Ø£ÙØ¶Ù„ Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¹Ø§Ù…
    
    'large': 'intfloat/multilingual-e5-large',
        # âœ… Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ© (1024 dim) - Ù„Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„ØªÙŠ ØªØ­ØªØ§Ø¬ Ø¯Ù‚Ø© Ø£ÙƒØ¨Ø±
    
    'small': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'
        # âœ… Ø³Ø±ÙŠØ¹ (384 dim) - Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø³Ø±ÙŠØ¹Ø©
}
```

### Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø®Ø¯Ù…Ø©

```python
from app.services.embedding_service import EmbeddingService
from app.db.database import get_db_session

async def example():
    async with get_db_session() as db:
        # Ø¥Ù†Ø´Ø§Ø¡ Ø®Ø¯Ù…Ø© embeddings
        service = EmbeddingService(db, model_name='default')
        
        # ØªÙˆÙ„ÙŠØ¯ embeddings Ù„Ù€ document
        result = await service.generate_document_embeddings(
            document_id=123,
            overwrite=False
        )
        print(f"âœ… Processed {result['processed_chunks']} chunks")
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† chunks Ù…Ø´Ø§Ø¨Ù‡Ø©
        similar = await service.find_similar_chunks(
            query="ÙØ³Ø® Ø§Ù„Ø¹Ù‚Ø¯ Ø¨Ø¯ÙˆÙ† Ø¥Ù†Ø°Ø§Ø±",
            top_k=10,
            threshold=0.75
        )
        
        for chunk in similar:
            print(f"ğŸ“„ Chunk {chunk['chunk_id']}: {chunk['similarity']:.2%}")
```

---

## ğŸŒ API Endpoints

### 1. ØªÙˆÙ„ÙŠØ¯ Embeddings Ù„Ù€ Document

```http
POST /api/v1/embeddings/documents/{document_id}/generate
```

**Parameters**:
- `document_id` (path): Ù…Ø¹Ø±Ù‘Ù Ø§Ù„Ù€ document
- `overwrite` (query): Ø¥Ø¹Ø§Ø¯Ø© ØªÙˆÙ„ÙŠØ¯ embeddings Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© (Ø§ÙØªØ±Ø§Ø¶ÙŠ: false)

**Response**:
```json
{
  "success": true,
  "message": "Generated embeddings for 45 chunks in document 123",
  "data": {
    "document_id": 123,
    "total_chunks": 45,
    "processed_chunks": 45,
    "failed_chunks": 0,
    "processing_time": "15.2s"
  },
  "errors": []
}
```

**Ù…Ø«Ø§Ù„ Ø¨Ù€ cURL**:
```bash
curl -X POST "http://localhost:8000/api/v1/embeddings/documents/123/generate?overwrite=false" \
  -H "Authorization: Bearer YOUR_JWT_TOKEN"
```

---

### 2. ØªÙˆÙ„ÙŠØ¯ Embeddings Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Chunks

```http
POST /api/v1/embeddings/chunks/batch-generate
```

**Parameters**:
- `chunk_ids` (query, multiple): Ù‚Ø§Ø¦Ù…Ø© Ù…Ø¹Ø±Ù‘ÙØ§Øª Ø§Ù„Ù€ chunks (max 1000)
- `overwrite` (query): Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªÙˆÙ„ÙŠØ¯ (Ø§ÙØªØ±Ø§Ø¶ÙŠ: false)

**Response**:
```json
{
  "success": true,
  "message": "Generated embeddings for 25 chunks",
  "data": {
    "total_chunks": 25,
    "processed_chunks": 25,
    "failed_chunks": 0,
    "processing_time": "4.3s"
  },
  "errors": []
}
```

**Ù…Ø«Ø§Ù„ Ø¨Ù€ cURL**:
```bash
curl -X POST "http://localhost:8000/api/v1/embeddings/chunks/batch-generate?chunk_ids=1&chunk_ids=2&chunk_ids=3" \
  -H "Authorization: Bearer YOUR_JWT_TOKEN"
```

---

### 3. Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ (Similarity Search) ğŸ”

```http
POST /api/v1/embeddings/search/similar
```

**Parameters**:
- `query` (query, required): Ù†Øµ Ø§Ù„Ø¨Ø­Ø« (Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø£Ùˆ Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©)
- `top_k` (query): Ø¹Ø¯Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ (1-100ØŒ Ø§ÙØªØ±Ø§Ø¶ÙŠ: 10)
- `threshold` (query): Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù„Ù„ØªØ´Ø§Ø¨Ù‡ (0.0-1.0ØŒ Ø§ÙØªØ±Ø§Ø¶ÙŠ: 0.7)
- `document_id` (query, optional): ØªØµÙÙŠØ© Ø­Ø³Ø¨ document
- `case_id` (query, optional): ØªØµÙÙŠØ© Ø­Ø³Ø¨ case
- `law_source_id` (query, optional): ØªØµÙÙŠØ© Ø­Ø³Ø¨ law source

**Response**:
```json
{
  "success": true,
  "message": "Found 8 similar chunks",
  "data": {
    "query": "ÙØ³Ø® Ø§Ù„Ø¹Ù‚Ø¯ Ø¨Ø¯ÙˆÙ† Ø¥Ù†Ø°Ø§Ø±",
    "results": [
      {
        "chunk_id": 456,
        "content": "ÙŠØ¬ÙˆØ² Ù„ØµØ§Ø­Ø¨ Ø§Ù„Ø¹Ù…Ù„ ÙØ³Ø® Ø§Ù„Ø¹Ù‚Ø¯ Ø¯ÙˆÙ† Ø¥Ù†Ø°Ø§Ø± ÙÙŠ Ø­Ø§Ù„Ø§Øª Ø§Ù„Ø¥Ø®Ù„Ø§Ù„ Ø§Ù„Ø¬Ø³ÙŠÙ…...",
        "similarity": 0.89,
        "document_id": 123,
        "chunk_index": 10,
        "law_source_id": 5,
        "article_id": 75,
        "tokens_count": 250
      },
      {
        "chunk_id": 789,
        "content": "Ø§Ù„Ù…Ø§Ø¯Ø© Ù§Ù¤: Ø¥Ø°Ø§ Ø£Ø®Ù„ Ø£Ø­Ø¯ Ø§Ù„Ø·Ø±ÙÙŠÙ† Ø¨Ø§Ù„Ø§Ù„ØªØ²Ø§Ù…Ø§Øª Ø§Ù„Ø¬ÙˆÙ‡Ø±ÙŠØ©...",
        "similarity": 0.85,
        "document_id": 123,
        "chunk_index": 15,
        "law_source_id": 5,
        "article_id": 74,
        "tokens_count": 180
      }
    ],
    "total_results": 8,
    "threshold": 0.7
  },
  "errors": []
}
```

**Ù…Ø«Ø§Ù„ Ø¨Ù€ cURL**:
```bash
curl -X POST "http://localhost:8000/api/v1/embeddings/search/similar?query=ÙØ³Ø®+Ø§Ù„Ø¹Ù‚Ø¯&top_k=10&threshold=0.75" \
  -H "Authorization: Bearer YOUR_JWT_TOKEN"
```

**Ù…Ø«Ø§Ù„ Ù…Ø¹ ØªØµÙÙŠØ©**:
```bash
# Ø§Ù„Ø¨Ø­Ø« ÙÙ‚Ø· ÙÙŠ Ù‚Ø¶Ø§ÙŠØ§ Ø§Ù„Ø¹Ù…Ù„
curl -X POST "http://localhost:8000/api/v1/embeddings/search/similar?query=Ø¥Ù†Ù‡Ø§Ø¡+Ø§Ù„Ø®Ø¯Ù…Ø©&case_id=25" \
  -H "Authorization: Bearer YOUR_JWT_TOKEN"

# Ø§Ù„Ø¨Ø­Ø« ÙÙ‚Ø· ÙÙŠ Ù†Ø¸Ø§Ù… Ø§Ù„Ø¹Ù…Ù„
curl -X POST "http://localhost:8000/api/v1/embeddings/search/similar?query=Ø³Ø§Ø¹Ø§Øª+Ø§Ù„Ø¹Ù…Ù„&law_source_id=3" \
  -H "Authorization: Bearer YOUR_JWT_TOKEN"
```

---

### 4. Ø­Ø§Ù„Ø© Embeddings Ù„Ù€ Document

```http
GET /api/v1/embeddings/documents/{document_id}/status
```

**Response**:
```json
{
  "success": true,
  "message": "Embedding status for document 123",
  "data": {
    "document_id": 123,
    "total_chunks": 50,
    "chunks_with_embeddings": 45,
    "chunks_without_embeddings": 5,
    "completion_percentage": 90.0,
    "status": "partial"
  },
  "errors": []
}
```

**Status Values**:
- `complete`: Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù€ chunks Ù„Ù‡Ø§ embeddings
- `partial`: Ø¨Ø¹Ø¶ Ø§Ù„Ù€ chunks Ù„Ù‡Ø§ embeddings
- `not_started`: Ù„Ø§ ÙŠÙˆØ¬Ø¯ embeddings Ø¨Ø¹Ø¯

---

### 5. Ø­Ø§Ù„Ø© Embeddings Ù„Ù„Ù†Ø¸Ø§Ù… Ø§Ù„ÙƒØ§Ù…Ù„

```http
GET /api/v1/embeddings/status
```

**Response**:
```json
{
  "success": true,
  "message": "Global embedding status",
  "data": {
    "total_chunks": 1250,
    "chunks_with_embeddings": 1000,
    "chunks_without_embeddings": 250,
    "completion_percentage": 80.0,
    "model_name": "default",
    "device": "cuda"
  },
  "errors": []
}
```

---

### 6. Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬

```http
GET /api/v1/embeddings/model-info
```

**Response**:
```json
{
  "success": true,
  "message": "Embedding model information",
  "data": {
    "model_name": "default",
    "model_path": "sentence-transformers/paraphrase-multilingual-mpnet-base-v2",
    "embedding_dimension": 768,
    "device": "cuda",
    "max_seq_length": 512,
    "batch_size": 32
  },
  "errors": []
}
```

---

## ğŸ”„ Ø³ÙƒØ±ÙŠØ¨Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¬Ù…Ø§Ø¹ÙŠØ©

### Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…

```bash
# 1. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù€ documents
python scripts/generate_embeddings_batch.py --all

# 2. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù€ chunks Ø¨Ø¯ÙˆÙ† embeddings ÙÙ‚Ø· (Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ)
python scripts/generate_embeddings_batch.py --pending

# 3. Ù…Ø¹Ø§Ù„Ø¬Ø© document Ù…Ø­Ø¯Ø¯
python scripts/generate_embeddings_batch.py --document-id 123

# 4. Ø§Ø³ØªØ¦Ù†Ø§Ù Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙØ§Ø´Ù„Ø©
python scripts/generate_embeddings_batch.py --resume

# 5. Ø¹Ø±Ø¶ Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù… ÙÙ‚Ø·
python scripts/generate_embeddings_batch.py --status

# 6. Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ù…Ø®ØªÙ„Ù
python scripts/generate_embeddings_batch.py --all --model large

# 7. ØªØºÙŠÙŠØ± batch size
python scripts/generate_embeddings_batch.py --pending --batch-size 64
```

### Ø§Ù„Ø®ÙŠØ§Ø±Ø§Øª

| Option | Description |
|--------|-------------|
| `--all` | Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù€ documents |
| `--pending` | Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù€ chunks Ø¨Ø¯ÙˆÙ† embeddings ÙÙ‚Ø· |
| `--document-id ID` | Ù…Ø¹Ø§Ù„Ø¬Ø© document Ù…Ø­Ø¯Ø¯ |
| `--resume` | Ø§Ø³ØªØ¦Ù†Ø§Ù Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙØ§Ø´Ù„Ø© |
| `--status` | Ø¹Ø±Ø¶ Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù… ÙˆØ§Ù„Ø®Ø±ÙˆØ¬ |
| `--model MODEL` | Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (default, large, small) |
| `--batch-size N` | Ø­Ø¬Ù… Ø§Ù„Ù€ batch Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© (Ø§ÙØªØ±Ø§Ø¶ÙŠ: 32) |

### Ù…Ø«Ø§Ù„ ÙƒØ§Ù…Ù„

```bash
# Ø®Ø·ÙˆØ© 1: Ø¹Ø±Ø¶ Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©
python scripts/generate_embeddings_batch.py --status

# Output:
# ================================================================================
# ğŸ“Š SYSTEM STATUS
# ================================================================================
# ğŸ“¦ Total chunks: 1500
# âœ… With embeddings: 500
# â³ Without embeddings: 1000
# ğŸ“ˆ Completion: 33.33%
# ================================================================================

# Ø®Ø·ÙˆØ© 2: Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù€ chunks Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ©
python scripts/generate_embeddings_batch.py --pending --model default

# Output:
# ================================================================================
# ğŸš€ Starting PENDING chunks embedding generation
# ================================================================================
# ğŸ“¦ Found 1000 pending chunks
# ğŸ“„ Chunks distributed across 25 documents
# 
# ============================================================
# ğŸ“„ Processing document 123: 45 chunks
# ============================================================
# âœ… Document 123 chunks processed
# ...
# 
# ================================================================================
# ğŸ“Š BATCH PROCESSING REPORT
# ================================================================================
# â±ï¸  Duration: 180.50 seconds (3.01 minutes)
# ğŸ“„ Documents:
#    Total: 0
#    Processed: 0
#    Failed: 0
# 
# ğŸ“¦ Chunks:
#    Total: 1000
#    Processed: 995
#    Failed: 5
# 
# âœ… Success Rate: 99.50%
# ================================================================================
```

### Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„ØªÙ‚Ø¯Ù…

Ø§Ù„Ø³ÙƒØ±ÙŠØ¨Øª ÙŠØ³Ø¬Ù„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª ÙÙŠ:
- **Console Output**: Ø¹Ø±Ø¶ Ù…Ø¨Ø§Ø´Ø± Ù„Ù„ØªÙ‚Ø¯Ù…
- **Log File**: `logs/embedding_batch.log`

---

## ğŸ¯ Ø­Ø§Ù„Ø§Øª Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…

### 1. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£ÙˆÙ„ÙŠØ© Ù„Ù„Ù†Ø¸Ø§Ù…

Ø¹Ù†Ø¯ Ø¥Ø¶Ø§ÙØ© Ù†Ø¸Ø§Ù… Ø§Ù„Ù€ embeddings Ù„Ø£ÙˆÙ„ Ù…Ø±Ø©:

```bash
# Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©
python scripts/generate_embeddings_batch.py --all --model default

# Ø£Ùˆ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø§ ÙŠÙ†Ù‚Øµ ÙÙ‚Ø·
python scripts/generate_embeddings_batch.py --pending
```

---

### 2. Ù…Ø¹Ø§Ù„Ø¬Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠØ© Ø¹Ù†Ø¯ Ø±ÙØ¹ document Ø¬Ø¯ÙŠØ¯

ÙÙŠ API endpoint Ù„Ø±ÙØ¹ Ø§Ù„Ù€ documents:

```python
@router.post("/upload")
async def upload_document(
    file: UploadFile,
    db: AsyncSession = Depends(get_db)
):
    # Ø±ÙØ¹ ÙˆØ­ÙØ¸ Ø§Ù„Ù€ document
    document = await save_document(file)
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© chunks
    chunks = await process_document_chunks(document)
    
    # âœ¨ ØªÙˆÙ„ÙŠØ¯ embeddings ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
    embedding_service = EmbeddingService(db)
    await embedding_service.generate_document_embeddings(document.id)
    
    return {"success": True, "document_id": document.id}
```

---

### 3. Ø¨Ø­Ø« Ø¯Ù„Ø§Ù„ÙŠ ÙÙŠ ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…

```python
@router.get("/search")
async def search_legal_content(
    query: str,
    db: AsyncSession = Depends(get_db)
):
    # Ø§Ø³ØªØ®Ø¯Ø§Ù… embedding service Ù„Ù„Ø¨Ø­Ø«
    service = EmbeddingService(db)
    
    results = await service.find_similar_chunks(
        query=query,
        top_k=10,
        threshold=0.7
    )
    
    # ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¨Ø¥Ø¶Ø§ÙØ© metadata
    enriched_results = []
    for result in results:
        chunk_data = {
            **result,
            "document_title": await get_document_title(result['document_id']),
            "law_name": await get_law_name(result['law_source_id']) if result['law_source_id'] else None
        }
        enriched_results.append(chunk_data)
    
    return {
        "success": True,
        "query": query,
        "results": enriched_results
    }
```

---

### 4. Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ø°ÙƒÙŠØ© Ù„Ù„Ù…Ø­Ø§Ù…ÙŠ

```python
async def suggest_related_articles(case_description: str, db: AsyncSession):
    """
    ÙŠÙ‚ØªØ±Ø­ Ù…ÙˆØ§Ø¯ Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø°Ø§Øª ØµÙ„Ø© Ø¨ÙˆØµÙ Ø§Ù„Ù‚Ø¶ÙŠØ©
    """
    service = EmbeddingService(db)
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† chunks Ù…Ø´Ø§Ø¨Ù‡Ø© Ù…Ù† Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† ÙÙ‚Ø·
    results = await service.find_similar_chunks(
        query=case_description,
        top_k=5,
        threshold=0.75,
        filters={"law_source_id": None}  # ÙÙ‚Ø· Ù…Ù† Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ†
    )
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©
    related_articles = []
    for result in results:
        if result['article_id']:
            article = await get_article(result['article_id'])
            related_articles.append({
                "article_number": article.article_number,
                "content": article.content,
                "law_name": article.law_source.name,
                "similarity": result['similarity']
            })
    
    return related_articles
```

---

### 5. ØªØ­Ù„ÙŠÙ„ ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ù‚Ø¶Ø§ÙŠØ§

```python
async def find_similar_cases(case_id: int, db: AsyncSession):
    """
    ÙŠØ¬Ø¯ Ù‚Ø¶Ø§ÙŠØ§ Ù…Ø´Ø§Ø¨Ù‡Ø© Ù„Ù‚Ø¶ÙŠØ© Ù…Ø­Ø¯Ø¯Ø©
    """
    # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù‚Ø¶ÙŠØ©
    case = await get_case(case_id)
    case_summary = case.sections.get('summary', case.description)
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù‚Ø¶Ø§ÙŠØ§ Ù…Ø´Ø§Ø¨Ù‡Ø©
    service = EmbeddingService(db)
    results = await service.find_similar_chunks(
        query=case_summary,
        top_k=10,
        threshold=0.70,
        filters={"case_id": None}  # Ø§Ø³ØªØ¨Ø¹Ø§Ø¯ Ù†ÙØ³ Ø§Ù„Ù‚Ø¶ÙŠØ©
    )
    
    # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø­Ø³Ø¨ Ø§Ù„Ù‚Ø¶ÙŠØ©
    similar_cases = {}
    for result in results:
        if result['case_id'] and result['case_id'] != case_id:
            if result['case_id'] not in similar_cases:
                similar_cases[result['case_id']] = {
                    "case_id": result['case_id'],
                    "max_similarity": result['similarity'],
                    "matching_sections": []
                }
            similar_cases[result['case_id']]['matching_sections'].append(result)
    
    return list(similar_cases.values())
```

---

## âš¡ Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª

### Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡

| Operation | Time | Notes |
|-----------|------|-------|
| ØªÙˆÙ„ÙŠØ¯ embedding Ù„Ù€ chunk ÙˆØ§Ø­Ø¯ | ~0.05s | GPU |
| ØªÙˆÙ„ÙŠØ¯ embedding Ù„Ù€ chunk ÙˆØ§Ø­Ø¯ | ~0.2s | CPU |
| Ù…Ø¹Ø§Ù„Ø¬Ø© 1000 chunks | ~5 min | GPU, batch_size=32 |
| Ù…Ø¹Ø§Ù„Ø¬Ø© 1000 chunks | ~15 min | CPU, batch_size=32 |
| Ø¨Ø­Ø« ÙÙŠ 10,000 embeddings | ~0.5s | In-memory cosine similarity |

### ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡

#### 1. Ø§Ø³ØªØ®Ø¯Ø§Ù… GPU

```python
# ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙˆÙØ± GPU
import torch
if torch.cuda.is_available():
    print(f"âœ… GPU available: {torch.cuda.get_device_name(0)}")
else:
    print("âš ï¸ Using CPU (slower)")
```

#### 2. Ø²ÙŠØ§Ø¯Ø© Batch Size

```python
# Ù„Ù„Ø£Ø¬Ù‡Ø²Ø© Ø§Ù„Ù‚ÙˆÙŠØ©
service = EmbeddingService(db)
service.batch_size = 64  # Ø²ÙŠØ§Ø¯Ø© Ù…Ù† 32 Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ
```

#### 3. Caching

Ø§Ù„Ù†Ø¸Ø§Ù… ÙŠØ®Ø²Ù† Ù…Ø¤Ù‚ØªØ§Ù‹ Ø¢Ø®Ø± 1000 embedding ØªÙ… ØªÙˆÙ„ÙŠØ¯Ù‡Ø§:

```python
# ÙÙŠ EmbeddingService
self._embedding_cache: Dict[str, List[float]] = {}
self._cache_max_size = 1000
```

#### 4. Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…ØªÙˆØ§Ø²ÙŠØ© (Ù„Ù„Ù…Ø³ØªÙ‚Ø¨Ù„)

```python
# Ø§Ø³ØªØ®Ø¯Ø§Ù… asyncio.gather Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…ØªÙˆØ§Ø²ÙŠØ©
import asyncio

async def process_multiple_documents(document_ids: List[int]):
    tasks = [
        service.generate_document_embeddings(doc_id)
        for doc_id in document_ids
    ]
    results = await asyncio.gather(*tasks)
    return results
```

---

## ğŸ” Ø§Ø³ØªÙƒØ´Ø§Ù Ø§Ù„Ø£Ø®Ø·Ø§Ø¡

### Ù…Ø´ÙƒÙ„Ø©: Model Ù„Ø§ ÙŠØªØ­Ù…Ù„

**Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶**:
```
RuntimeError: Failed to initialize embedding model
```

**Ø§Ù„Ø­Ù„**:
```bash
# ØªØ«Ø¨ÙŠØª sentence-transformers
pip install sentence-transformers

# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª (Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬)
ping huggingface.co

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØ¯ÙˆÙŠØ§Ù‹
python -c "from sentence_transformers import SentenceTransformer; SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')"
```

---

### Ù…Ø´ÙƒÙ„Ø©: Ù†ÙØ§Ø¯ Ø§Ù„Ø°Ø§ÙƒØ±Ø©

**Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶**:
```
CUDA out of memory
# Ø£Ùˆ
MemoryError
```

**Ø§Ù„Ø­Ù„**:
```python
# 1. ØªÙ‚Ù„ÙŠÙ„ batch_size
service.batch_size = 16  # Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† 32

# 2. Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ø£ØµØºØ±
service = EmbeddingService(db, model_name='small')

# 3. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¹Ù„Ù‰ CPU
import torch
torch.cuda.set_device(-1)  # Force CPU
```

---

### Ù…Ø´ÙƒÙ„Ø©: Ø¨Ø·Ø¡ Ø§Ù„Ø¨Ø­Ø«

**Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶**:
Ø§Ù„Ø¨Ø­Ø« ÙŠØ³ØªØºØ±Ù‚ Ø£ÙƒØ«Ø± Ù…Ù† 5 Ø«ÙˆØ§Ù†Ù

**Ø§Ù„Ø­Ù„**:
```python
# Ø§Ø³ØªØ®Ø¯Ø§Ù… FAISS Ù„Ù„Ø¨Ø­Ø« Ø§Ù„Ø³Ø±ÙŠØ¹ (Ù„Ù„Ù…Ø³ØªÙ‚Ø¨Ù„)
import faiss
import numpy as np

# Ø¨Ù†Ø§Ø¡ FAISS index
embeddings = [json.loads(chunk.embedding_vector) for chunk in chunks]
embeddings_array = np.array(embeddings).astype('float32')

index = faiss.IndexFlatIP(768)  # Inner product (cosine similarity)
index.add(embeddings_array)

# Ø§Ù„Ø¨Ø­Ø«
query_embedding = service._encode_text(query)
D, I = index.search(np.array([query_embedding]).astype('float32'), top_k)
```

---

### Ù…Ø´ÙƒÙ„Ø©: JSON serialization error

**Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶**:
```
TypeError: Object of type 'ndarray' is not JSON serializable
```

**Ø§Ù„Ø­Ù„**:
```python
# ØªØ­ÙˆÙŠÙ„ numpy array Ø¥Ù„Ù‰ list
import json
embedding_list = embedding.tolist()
chunk.embedding_vector = json.dumps(embedding_list)
```

---

## ğŸ“ˆ Ù…Ø±Ø§Ù‚Ø¨Ø© ÙˆØªØ³Ø¬ÙŠÙ„

### Logging

Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ù…Ø³Ø¬Ù„Ø©:

```python
# ÙÙŠ embedding_service.py
logger.info("âœ… Model initialized successfully")
logger.warning("âš ï¸ Truncating text from 2000 to 2048 characters")
logger.error("âŒ Failed to generate embedding for chunk 123")
```

### Metrics

ØªØªØ¨Ø¹ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª:

```python
{
  "total_chunks": 1500,
  "processed_chunks": 1450,
  "failed_chunks": 50,
  "processing_time": "15.2s",
  "success_rate": 96.67
}
```

---

## ğŸš€ Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©

### Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1: âœ… ØªÙ…

- [x] Ø¥Ù†Ø´Ø§Ø¡ `embedding_service.py`
- [x] Ø¥Ù†Ø´Ø§Ø¡ `embedding_router.py`
- [x] ØªØ­Ø¯ÙŠØ« `KnowledgeChunk` model
- [x] Ø¥Ù†Ø´Ø§Ø¡ migration
- [x] Ø¥Ù†Ø´Ø§Ø¡ Ø³ÙƒØ±ÙŠØ¨Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¬Ù…Ø§Ø¹ÙŠØ©
- [x] Ø§Ù„ØªÙˆØ«ÙŠÙ‚ Ø§Ù„ÙƒØ§Ù…Ù„

### Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2: Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª

- [ ] Ø§Ø³ØªØ®Ø¯Ø§Ù… FAISS Ù„Ù„Ø¨Ø­Ø« Ø§Ù„Ø³Ø±ÙŠØ¹
- [ ] Ø¯Ø¹Ù… ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¨Ø¯ÙˆÙ† downtime
- [ ] API Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø®ØªÙ„ÙØ©
- [ ] Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…ØªÙˆØ§Ø²ÙŠØ© Ù„Ù„Ù€ documents
- [ ] ØªÙƒØ§Ù…Ù„ Ù…Ø¹ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªØ¬Ù‡Ø§Øª (pgvector)

### Ø§Ù„Ù…Ø±Ø­Ù„Ø© 3: Ù…ÙŠØ²Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø©

- [ ] Fine-tuning Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ Ù†ØµÙˆØµ Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø³Ø¹ÙˆØ¯ÙŠØ©
- [ ] Hybrid search (semantic + keyword)
- [ ] ØªØ­Ù„ÙŠÙ„ ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ù‚Ø¶Ø§ÙŠØ§ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
- [ ] Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ø°ÙƒÙŠØ© Ù„Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©
- [ ] ØªØµÙ†ÙŠÙ ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù„Ù„Ù†ØµÙˆØµ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©

---

## ğŸ“ Ø£Ù…Ø«Ù„Ø© Ø¹Ù…Ù„ÙŠØ©

### Ù…Ø«Ø§Ù„ 1: Ù…Ø¹Ø§Ù„Ø¬Ø© document Ø¬Ø¯ÙŠØ¯

```python
from app.services.embedding_service import EmbeddingService
from app.db.database import get_db_session

async def process_new_document(document_id: int):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© document Ø¬Ø¯ÙŠØ¯ ÙˆØªÙˆÙ„ÙŠØ¯ embeddings"""
    async with get_db_session() as db:
        service = EmbeddingService(db, model_name='default')
        
        # ØªÙˆÙ„ÙŠØ¯ embeddings
        result = await service.generate_document_embeddings(document_id)
        
        if result['success']:
            print(f"âœ… Processed {result['processed_chunks']} chunks")
            print(f"â±ï¸  Time: {result['processing_time']}")
        else:
            print(f"âŒ Failed: {result.get('error')}")
```

---

### Ù…Ø«Ø§Ù„ 2: Ø¨Ø­Ø« Ø°ÙƒÙŠ Ø¹Ù† Ù…ÙˆØ§Ø¯ Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©

```python
async def smart_legal_search(query: str):
    """Ø¨Ø­Ø« Ø°ÙƒÙŠ Ø¹Ù† Ù…ÙˆØ§Ø¯ Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø°Ø§Øª ØµÙ„Ø©"""
    async with get_db_session() as db:
        service = EmbeddingService(db)
        
        # Ø§Ù„Ø¨Ø­Ø«
        results = await service.find_similar_chunks(
            query=query,
            top_k=5,
            threshold=0.75,
            filters={"law_source_id": 3}  # Ù†Ø¸Ø§Ù… Ø§Ù„Ø¹Ù…Ù„ ÙÙ‚Ø·
        )
        
        print(f"ğŸ” Search results for: '{query}'")
        print("=" * 60)
        
        for i, result in enumerate(results, 1):
            print(f"\n{i}. Similarity: {result['similarity']:.2%}")
            print(f"   Content: {result['content'][:100]}...")
            print(f"   Article ID: {result['article_id']}")

# Ø§Ø³ØªØ®Ø¯Ø§Ù…
await smart_legal_search("Ø¥Ù†Ù‡Ø§Ø¡ Ø¹Ù‚Ø¯ Ø§Ù„Ø¹Ù…Ù„ Ø¨Ø¯ÙˆÙ† Ø¥Ù†Ø°Ø§Ø±")
```

---

### Ù…Ø«Ø§Ù„ 3: ØªØ­Ù„ÙŠÙ„ ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ù‚Ø¶Ø§ÙŠØ§

```python
async def analyze_case_similarity(case_id: int):
    """ØªØ­Ù„ÙŠÙ„ ØªØ´Ø§Ø¨Ù‡ Ù‚Ø¶ÙŠØ© Ù…Ø¹ Ù‚Ø¶Ø§ÙŠØ§ Ø£Ø®Ø±Ù‰"""
    async with get_db_session() as db:
        service = EmbeddingService(db)
        
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù‚Ø¶ÙŠØ©
        case = await get_case(case_id)
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù‚Ø¶Ø§ÙŠØ§ Ù…Ø´Ø§Ø¨Ù‡Ø©
        results = await service.find_similar_chunks(
            query=case.description,
            top_k=10,
            threshold=0.70
        )
        
        # ØªØ¬Ù…ÙŠØ¹ Ø­Ø³Ø¨ Ø§Ù„Ù‚Ø¶ÙŠØ©
        similar_cases = {}
        for result in results:
            cid = result['case_id']
            if cid and cid != case_id:
                if cid not in similar_cases:
                    similar_cases[cid] = []
                similar_cases[cid].append(result)
        
        print(f"ğŸ“Š Found {len(similar_cases)} similar cases")
        for cid, chunks in similar_cases.items():
            avg_similarity = sum(c['similarity'] for c in chunks) / len(chunks)
            print(f"   Case {cid}: {avg_similarity:.2%} similarity")
```

---

## ğŸ¯ Ø§Ù„Ø®Ù„Ø§ØµØ©

Ù†Ø¸Ø§Ù… Ø§Ù„Ù€ embeddings Ø¬Ø§Ù‡Ø² Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ ÙˆÙŠÙˆÙØ±:

âœ… **API Ø´Ø§Ù…Ù„** Ù„ØªÙˆÙ„ÙŠØ¯ ÙˆØ¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù€ embeddings  
âœ… **Ø¨Ø­Ø« Ø¯Ù„Ø§Ù„ÙŠ Ø°ÙƒÙŠ** Ù„Ù„Ù†ØµÙˆØµ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©  
âœ… **Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¬Ù…Ø§Ø¹ÙŠØ©** Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ©  
âœ… **Ø£Ø¯Ø§Ø¡ Ø¹Ø§Ù„Ù** Ù…Ø¹ Ø¯Ø¹Ù… GPU  
âœ… **Ù…Ø±ÙˆÙ†Ø© ÙƒØ§Ù…Ù„Ø©** ÙÙŠ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù†Ù…Ø§Ø°Ø¬  
âœ… **ØªÙˆØ«ÙŠÙ‚ Ø´Ø§Ù…Ù„** Ù…Ø¹ Ø£Ù…Ø«Ù„Ø© Ø¹Ù…Ù„ÙŠØ©  

**Ø¬Ø§Ù‡Ø² Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙÙˆØ±ÙŠ! ğŸš€**

---

**Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ«**: 8 ÙŠÙ†Ø§ÙŠØ± 2025  
**Ø§Ù„Ø¥ØµØ¯Ø§Ø±**: 1.0  
**Ø§Ù„Ù…Ø·ÙˆÙ‘Ø±**: Legatoo AI Legal Assistant Team
