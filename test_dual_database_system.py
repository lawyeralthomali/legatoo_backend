"""
Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ù…Ø¹ Ø¯Ø¹Ù… Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø²Ø¯ÙˆØ¬Ø©
"""

import asyncio
import json
import requests
from app.services.document_parser_service import (
    VectorstoreManager, 
    DualDatabaseManager, 
    LegalDocumentParser,
    DocumentUploadService
)
from app.db.database import AsyncSessionLocal
from app.models.legal_knowledge import KnowledgeDocument, KnowledgeChunk

async def test_vectorstore_manager():
    """Ø§Ø®ØªØ¨Ø§Ø± VectorstoreManager (Singleton)"""
    print("ğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± VectorstoreManager...")
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø«ÙŠÙ„ÙŠÙ† Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Singleton
    manager1 = VectorstoreManager()
    manager2 = VectorstoreManager()
    
    # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù†Ù‡Ù…Ø§ Ù†ÙØ³ Ø§Ù„Ù…Ø«ÙŠÙ„
    assert manager1 is manager2, "âŒ VectorstoreManager Ù„ÙŠØ³ Singleton!"
    print("âœ… VectorstoreManager Singleton ÙŠØ¹Ù…Ù„ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­")
    
    # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª
    vectorstore = manager1.get_vectorstore()
    embeddings = manager1.get_embeddings()
    text_splitter = manager1.get_text_splitter()
    
    assert vectorstore is not None, "âŒ Vectorstore ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯"
    assert embeddings is not None, "âŒ Embeddings ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯"
    assert text_splitter is not None, "âŒ Text splitter ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯"
    
    print("âœ… Ø¬Ù…ÙŠØ¹ Ù…ÙƒÙˆÙ†Ø§Øª VectorstoreManager ØªØ¹Ù…Ù„ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­")

async def test_dual_database_manager():
    """Ø§Ø®ØªØ¨Ø§Ø± DualDatabaseManager"""
    print("\nğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± DualDatabaseManager...")
    
    async with AsyncSessionLocal() as db:
        dual_manager = DualDatabaseManager(db)
        
        # Ø§Ø®ØªØ¨Ø§Ø± Ø¥Ø¶Ø§ÙØ© chunk ØªØ¬Ø±ÙŠØ¨ÙŠ
        test_chunk = KnowledgeChunk(
            document_id=1,
            chunk_index=0,
            content="Ù‡Ø°Ø§ Ù†Øµ ØªØ¬Ø±ÙŠØ¨ÙŠ Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±",
            tokens_count=10,
            verified_by_admin=False
        )
        
        test_metadata = {
            "test": True,
            "article_number": "Ø§Ù„Ù…Ø§Ø¯Ø© 1",
            "law_name": "Ù‚Ø§Ù†ÙˆÙ† ØªØ¬Ø±ÙŠØ¨ÙŠ"
        }
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥Ø¶Ø§ÙØ© chunk (Ù‚Ø¯ ØªÙØ´Ù„ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù‡Ù†Ø§Ùƒ document_id=1)
        try:
            success = await dual_manager.add_chunk_to_both_databases(
                test_chunk, test_chunk.content, test_metadata
            )
            if success:
                print("âœ… Ø¥Ø¶Ø§ÙØ© chunk Ø¥Ù„Ù‰ ÙƒÙ„Ø§ Ø§Ù„Ù†Ø¸Ø§Ù…ÙŠÙ† Ù†Ø¬Ø­Øª")
                
                # Ø§Ø®ØªØ¨Ø§Ø± Ø­Ø°Ù chunk
                delete_success = await dual_manager.delete_chunk_from_both_databases(test_chunk.id)
                if delete_success:
                    print("âœ… Ø­Ø°Ù chunk Ù…Ù† ÙƒÙ„Ø§ Ø§Ù„Ù†Ø¸Ø§Ù…ÙŠÙ† Ù†Ø¬Ø­")
                else:
                    print("âš ï¸ Ø­Ø°Ù chunk ÙØ´Ù„")
            else:
                print("âš ï¸ Ø¥Ø¶Ø§ÙØ© chunk ÙØ´Ù„Øª (Ø±Ø¨Ù…Ø§ Ø¨Ø³Ø¨Ø¨ Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ document_id=1)")
        except Exception as e:
            print(f"âš ï¸ Ø§Ø®ØªØ¨Ø§Ø± Ø¥Ø¶Ø§ÙØ© chunk ÙØ´Ù„: {e}")
        
        # Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ù†Ø¸Ø§Ù…ÙŠÙ†
        try:
            sync_stats = await dual_manager.sync_database_states()
            print(f"âœ… Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ù†Ø¸Ø§Ù…ÙŠÙ† Ù†Ø¬Ø­Øª: {sync_stats}")
        except Exception as e:
            print(f"âš ï¸ Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ù†Ø¸Ø§Ù…ÙŠÙ† ÙØ´Ù„Øª: {e}")

async def test_document_parser():
    """Ø§Ø®ØªØ¨Ø§Ø± LegalDocumentParser Ø§Ù„Ù…Ø­Ø¯Ø«"""
    print("\nğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± LegalDocumentParser...")
    
    async with AsyncSessionLocal() as db:
        parser = LegalDocumentParser(db)
        
        # Ø§Ø®ØªØ¨Ø§Ø± ÙˆØ¬ÙˆØ¯ dual_db_manager
        assert parser.dual_db_manager is not None, "âŒ dual_db_manager ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯"
        print("âœ… LegalDocumentParser ØªÙ… ØªØ­Ø¯ÙŠØ«Ù‡ Ø¨Ù†Ø¬Ø§Ø­")
        
        # Ø§Ø®ØªØ¨Ø§Ø± text splitter
        test_text = "Ù‡Ø°Ø§ Ù†Øµ Ø·ÙˆÙŠÙ„ Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±. ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¹Ø¯Ø© Ø¬Ù…Ù„. ÙŠØ¬Ø¨ ØªÙ‚Ø³ÙŠÙ…Ù‡ Ø¥Ù„Ù‰ chunks Ù…ØªØ¹Ø¯Ø¯Ø©."
        chunks = parser.dual_db_manager.text_splitter.split_text(test_text)
        
        assert len(chunks) > 0, "âŒ Text splitter Ù„Ø§ ÙŠØ¹Ù…Ù„"
        print(f"âœ… Text splitter ÙŠØ¹Ù…Ù„: ØªÙ… ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ {len(chunks)} chunks")

async def test_document_upload_service():
    """Ø§Ø®ØªØ¨Ø§Ø± DocumentUploadService Ø§Ù„Ù…Ø­Ø¯Ø«"""
    print("\nğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± DocumentUploadService...")
    
    async with AsyncSessionLocal() as db:
        service = DocumentUploadService(db)
        
        # Ø§Ø®ØªØ¨Ø§Ø± ÙˆØ¬ÙˆØ¯ dual_db_manager
        assert service.dual_db_manager is not None, "âŒ dual_db_manager ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯"
        print("âœ… DocumentUploadService ØªÙ… ØªØ­Ø¯ÙŠØ«Ù‡ Ø¨Ù†Ø¬Ø§Ø­")
        
        # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…ÙŠÙ†
        try:
            status = await service.get_database_status()
            print(f"âœ… Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…ÙŠÙ†: {status}")
        except Exception as e:
            print(f"âš ï¸ ÙØ´Ù„ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…ÙŠÙ†: {e}")

def test_api_endpoints():
    """Ø§Ø®ØªØ¨Ø§Ø± API endpoints Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©"""
    print("\nğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± API endpoints Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©...")
    
    base_url = "http://localhost:8000"
    
    # Ø§Ø®ØªØ¨Ø§Ø± Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…ÙŠÙ†
    try:
        response = requests.get(f"{base_url}/api/v1/documents/database/status")
        if response.status_code == 200:
            print("âœ… GET /database/status ÙŠØ¹Ù…Ù„")
            data = response.json()
            print(f"ğŸ“Š Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…ÙŠÙ†: {data.get('data', {}).get('synchronization', {})}")
        else:
            print(f"âš ï¸ GET /database/status ÙØ´Ù„: {response.status_code}")
    except Exception as e:
        print(f"âš ï¸ Ø§Ø®ØªØ¨Ø§Ø± API ÙØ´Ù„: {e}")
    
    # Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ù†Ø¸Ø§Ù…ÙŠÙ†
    try:
        response = requests.post(f"{base_url}/api/v1/documents/database/sync")
        if response.status_code == 200:
            print("âœ… POST /database/sync ÙŠØ¹Ù…Ù„")
        else:
            print(f"âš ï¸ POST /database/sync ÙØ´Ù„: {response.status_code}")
    except Exception as e:
        print(f"âš ï¸ Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø²Ø§Ù…Ù†Ø© API ÙØ´Ù„: {e}")

async def test_json_parsing_with_dual_db():
    """Ø§Ø®ØªØ¨Ø§Ø± ØªØ­Ù„ÙŠÙ„ JSON Ù…Ø¹ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø²Ø¯ÙˆØ¬Ø©"""
    print("\nğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± ØªØ­Ù„ÙŠÙ„ JSON Ù…Ø¹ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø²Ø¯ÙˆØ¬Ø©...")
    
    # Ø¨ÙŠØ§Ù†Ø§Øª JSON ØªØ¬Ø±ÙŠØ¨ÙŠØ©
    test_json_data = {
        "law_sources": {
            "name": "Ù‚Ø§Ù†ÙˆÙ† ØªØ¬Ø±ÙŠØ¨ÙŠ",
            "type": "law",
            "jurisdiction": "Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©",
            "issuing_authority": "ÙˆØ²Ø§Ø±Ø© Ø§Ù„ØªØ¬Ø§Ø±Ø©",
            "issue_date": "2024-01-01",
            "articles": [
                {
                    "article": "Ø§Ù„Ù…Ø§Ø¯Ø© 1",
                    "title": "ØªØ¹Ø±ÙŠÙØ§Øª",
                    "text": "Ù‡Ø°Ø§ Ù†Øµ Ø§Ù„Ù…Ø§Ø¯Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ Ù…Ù† Ø§Ù„Ù‚Ø§Ù†ÙˆÙ† Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠ. ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ØªØ¹Ø±ÙŠÙØ§Øª Ù…Ù‡Ù…Ø© Ù„Ù„Ù‚Ø§Ù†ÙˆÙ†.",
                    "order_index": 1
                },
                {
                    "article": "Ø§Ù„Ù…Ø§Ø¯Ø© 2",
                    "title": "Ø§Ù„ØªØ·Ø¨ÙŠÙ‚",
                    "text": "Ù‡Ø°Ø§ Ù†Øµ Ø§Ù„Ù…Ø§Ø¯Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ© Ù…Ù† Ø§Ù„Ù‚Ø§Ù†ÙˆÙ† Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠ. ÙŠØªØ­Ø¯Ø« Ø¹Ù† ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†.",
                    "order_index": 2
                }
            ]
        }
    }
    
    # Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ù…Ù„Ù ØªØ¬Ø±ÙŠØ¨ÙŠ
    test_file_path = "test_dual_db_document.json"
    with open(test_file_path, 'w', encoding='utf-8') as f:
        json.dump(test_json_data, f, ensure_ascii=False, indent=2)
    
    try:
        async with AsyncSessionLocal() as db:
            # Ø¥Ù†Ø´Ø§Ø¡ ÙˆØ«ÙŠÙ‚Ø© ØªØ¬Ø±ÙŠØ¨ÙŠØ©
            document = KnowledgeDocument(
                title="ÙˆØ«ÙŠÙ‚Ø© ØªØ¬Ø±ÙŠØ¨ÙŠØ©",
                category="law",
                file_path=test_file_path,
                file_hash="test_hash",
                source_type='uploaded',
                status='raw',
                uploaded_by=1
            )
            
            db.add(document)
            await db.commit()
            await db.refresh(document)
            
            # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªØ­Ù„ÙŠÙ„
            parser = LegalDocumentParser(db)
            law_sources, articles, chunks = await parser.parse_document(
                test_file_path, document, {"filename": "test.json"}
            )
            
            print(f"âœ… ØªØ­Ù„ÙŠÙ„ JSON Ù†Ø¬Ø­:")
            print(f"   - Ù…ØµØ§Ø¯Ø± Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©: {len(law_sources)}")
            print(f"   - Ù…ÙˆØ§Ø¯: {len(articles)}")
            print(f"   - chunks: {len(chunks)}")
            
            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ©
            await db.delete(document)
            await db.commit()
            
    except Exception as e:
        print(f"âŒ Ø§Ø®ØªØ¨Ø§Ø± ØªØ­Ù„ÙŠÙ„ JSON ÙØ´Ù„: {e}")
    
    finally:
        # Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠ
        import os
        if os.path.exists(test_file_path):
            os.remove(test_file_path)

async def main():
    """ØªØ´ØºÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª"""
    print("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ù…Ø¹ Ø¯Ø¹Ù… Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø²Ø¯ÙˆØ¬Ø©\n")
    
    try:
        await test_vectorstore_manager()
        await test_dual_database_manager()
        await test_document_parser()
        await test_document_upload_service()
        await test_json_parsing_with_dual_db()
        
        print("\n" + "="*60)
        print("ğŸ‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù…ÙƒØªÙ…Ù„Ø©!")
        print("="*60)
        
    except Exception as e:
        print(f"\nâŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª: {e}")
    
    # Ø§Ø®ØªØ¨Ø§Ø± API endpoints (ÙŠØªØ·Ù„Ø¨ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø®Ø§Ø¯Ù…)
    print("\nğŸ“¡ Ø§Ø®ØªØ¨Ø§Ø± API endpoints...")
    test_api_endpoints()

if __name__ == "__main__":
    asyncio.run(main())
