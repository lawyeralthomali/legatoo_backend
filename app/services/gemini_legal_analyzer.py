"""
Gemini Legal Analyzer - Ù…Ø­Ø±Ùƒ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ

This service uses Google's Gemini AI to perform comprehensive legal analysis
for Arabic legal texts, specifically tailored for Saudi Arabian law.
"""

import logging
import json
import os
from typing import Dict, Any, List, Optional
from datetime import datetime
import google.generativeai as genai
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

logger = logging.getLogger(__name__)


class GeminiLegalAnalyzer:
    """
    Ù…Ø­ÙˆØ± Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù… - ÙŠØ³ØªØ®Ø¯Ù… Gemini Ù„ÙÙ‡Ù… ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†.
    
    Features:
    - Comprehensive legal analysis using Gemini Pro
    - Arabic legal text understanding
    - Case classification and categorization
    - Legal strategy recommendations
    - Risk assessment
    - Procedural guidance
    """
    
    def __init__(self, api_key: Optional[str] = None):
        """
        Initialize Gemini Legal Analyzer.
        
        Args:
            api_key: Google AI API key (optional, defaults to env variable)
        """
        self.api_key = api_key or os.getenv("GOOGLE_AI_API_KEY")
        
        if not self.api_key:
            logger.warning("âš ï¸ GOOGLE_AI_API_KEY not found. Gemini features will be disabled.")
            self.enabled = False
            return
        
        try:
            # Configure Gemini
            genai.configure(api_key=self.api_key)
            
            # Initialize model
            self.model = genai.GenerativeModel('gemini-pro')
            
            # Generation config
            self.generation_config = {
                'temperature': 0.3,  # Lower for more focused legal analysis
                'top_p': 0.8,
                'top_k': 40,
                'max_output_tokens': 4096,
            }
            
            # Safety settings (allow legal content)
            self.safety_settings = [
                {
                    "category": "HARM_CATEGORY_HARASSMENT",
                    "threshold": "BLOCK_NONE"
                },
                {
                    "category": "HARM_CATEGORY_HATE_SPEECH",
                    "threshold": "BLOCK_NONE"
                },
                {
                    "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                    "threshold": "BLOCK_MEDIUM_AND_ABOVE"
                },
                {
                    "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
                    "threshold": "BLOCK_NONE"
                }
            ]
            
            self.enabled = True
            logger.info("âœ… Gemini Legal Analyzer initialized successfully")
            
        except Exception as e:
            logger.error(f"âŒ Failed to initialize Gemini: {str(e)}")
            self.enabled = False
    
    def _create_comprehensive_prompt(self, case_text: str) -> str:
        """
        Ø¥Ù†Ø´Ø§Ø¡ prompt Ø´Ø§Ù…Ù„ Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„.
        
        Args:
            case_text: Ù†Øµ Ø§Ù„Ù‚Ø¶ÙŠØ© Ù„Ù„ØªØ­Ù„ÙŠÙ„
            
        Returns:
            Prompt Ù…Ù†Ø¸Ù… Ù„Ù„ØªØ­Ù„ÙŠÙ„
        """
        prompt = f"""Ø£Ù†Øª Ù…Ø³ØªØ´Ø§Ø± Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø®Ø¨ÙŠØ± ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØŒ Ù„Ø¯ÙŠÙƒ Ø®Ø¨Ø±Ø© 20 Ø¹Ø§Ù…Ø§Ù‹ ÙÙŠ Ø§Ù„Ù…Ø­Ø§ÙƒÙ… ÙˆØ§Ù„Ù‚Ø¶Ø§ÙŠØ§ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©.

**Ø§Ù„Ù‚Ø¶ÙŠØ© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ØªØ­Ù„ÙŠÙ„Ù‡Ø§:**
"{case_text}"

**Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ù…Ù†Ùƒ Ø¥Ø¹Ø¯Ø§Ø¯ ØªØ­Ù„ÙŠÙ„ Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø´Ø§Ù…Ù„ ÙˆÙ…Ø­ØªØ±Ù ÙŠØªØ¶Ù…Ù†:**

## 1ï¸âƒ£ Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø¯Ù‚ÙŠÙ‚ Ù„Ù„Ù‚Ø¶ÙŠØ©
- **Ø§Ù„Ù†ÙˆØ¹ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ**: (Ù…Ø¯Ù†ÙŠØŒ Ø¬Ù†Ø§Ø¦ÙŠØŒ Ø¹Ù…Ù„ØŒ ØªØ¬Ø§Ø±ÙŠØŒ Ø¥Ø¯Ø§Ø±ÙŠØŒ Ø£Ø­ÙˆØ§Ù„ Ø´Ø®ØµÙŠØ©ØŒ Ø£Ùˆ ØºÙŠØ±Ù‡)
- **Ø§Ù„Ø¯Ø±Ø¬Ø©**: (Ø¨Ø³ÙŠØ·Ø©ØŒ Ù…ØªÙˆØ³Ø·Ø©ØŒ Ù…Ø¹Ù‚Ø¯Ø©)
- **Ø¯Ø±Ø¬Ø© Ø§Ù„Ø«Ù‚Ø©**: (Ù†Ø³Ø¨Ø© Ù…Ø¦ÙˆÙŠØ© Ù…Ù† 0-100%)
- **Ø§Ù„Ø£Ø·Ø±Ø§Ù**: Ø­Ø¯Ø¯ Ø§Ù„Ø£Ø·Ø±Ø§Ù Ø§Ù„Ù…Ø¹Ù†ÙŠØ© (Ù…Ø¯Ø¹ÙŠØŒ Ù…Ø¯Ø¹Ù‰ Ø¹Ù„ÙŠÙ‡ØŒ Ø´Ù‡ÙˆØ¯ØŒ Ø¥Ù„Ø®)

## 2ï¸âƒ£ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø§Ù„Ù…ÙØµÙ„
- **Ø§Ù„ÙˆØ§Ù‚Ø¹Ø© Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©**: Ù…Ø§ Ù‡ÙŠ Ø§Ù„ÙˆÙ‚Ø§Ø¦Ø¹ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©ØŸ
- **Ø§Ù„Ø­Ù‚ÙˆÙ‚ ÙˆØ§Ù„Ø§Ù„ØªØ²Ø§Ù…Ø§Øª**: Ù…Ø§ Ù‡ÙŠ Ø­Ù‚ÙˆÙ‚ ÙƒÙ„ Ø·Ø±Ù ÙˆÙ…Ø§ Ù‡ÙŠ Ø§Ù„ØªØ²Ø§Ù…Ø§ØªÙ‡ØŸ
- **Ø§Ù„Ø£Ø¯Ù„Ø© Ø§Ù„Ù…ØªÙˆÙØ±Ø©**: Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ø£Ø¯Ù„Ø© Ø§Ù„Ø¸Ø§Ù‡Ø±Ø© ÙÙŠ Ø§Ù„Ù‚Ø¶ÙŠØ©ØŸ
- **Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©**: Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„ÙˆØ§Ø¬Ø¨ Ø§ØªØ®Ø§Ø°Ù‡Ø§ØŸ

## 3ï¸âƒ£ Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† ÙˆØ§Ù„Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ù…Ù†Ø·Ø¨Ù‚Ø©
- Ø§Ø°ÙƒØ± **Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† ÙˆØ§Ù„Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©** Ø°Ø§Øª Ø§Ù„Ø¹Ù„Ø§Ù‚Ø© Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø©
- Ø§Ø°ÙƒØ± **Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…ÙˆØ§Ø¯** Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© Ø¥Ù† Ø£Ù…ÙƒÙ†
- Ø§Ø´Ø±Ø­ **ÙƒÙŠÙÙŠØ© Ø§Ù„Ø§Ù†Ø·Ø¨Ø§Ù‚** Ø¹Ù„Ù‰ Ù‡Ø°Ù‡ Ø§Ù„Ù‚Ø¶ÙŠØ©
- Ø­Ø¯Ø¯ **Ø§Ù„Ø´Ø±ÙˆØ· ÙˆØ§Ù„Ø£Ø­ÙƒØ§Ù…** Ø§Ù„ÙˆØ§Ø¬Ø¨ ØªÙˆØ§ÙØ±Ù‡Ø§

## 4ï¸âƒ£ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø«ØºØ±Ø§Øª ÙˆØ§Ù„ÙØ±Øµ
- **Ø«ØºØ±Ø§Øª Ø¥Ø¬Ø±Ø§Ø¦ÙŠØ©**: Ù‡Ù„ Ù‡Ù†Ø§Ùƒ Ø£Ø®Ø·Ø§Ø¡ Ø£Ùˆ Ù†Ù‚Ø§Ø· Ø¶Ø¹Ù Ø¥Ø¬Ø±Ø§Ø¦ÙŠØ©ØŸ
- **Ù†Ù‚Ø§Ø· Ø¶Ø¹Ù Ø§Ù„Ø®ØµÙ…**: Ù…Ø§ Ù‡ÙŠ Ù†Ù‚Ø§Ø· Ø§Ù„Ø¶Ø¹Ù ÙÙŠ Ù…ÙˆÙ‚Ù Ø§Ù„Ø·Ø±Ù Ø§Ù„Ø¢Ø®Ø±ØŸ
- **ÙØ±Øµ Ù„Ù„Ø§Ø³ØªÙØ§Ø¯Ø©**: Ù…Ø§ Ù‡ÙŠ Ø§Ù„ÙØ±Øµ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„ØªÙŠ ÙŠÙ…ÙƒÙ† Ø§Ø³ØªØºÙ„Ø§Ù„Ù‡Ø§ØŸ
- **Ù…Ø®Ø§Ø·Ø± ÙŠØ¬Ø¨ ØªØ¬Ù†Ø¨Ù‡Ø§**: Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ù…Ø®Ø§Ø·Ø± Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„ØªÙŠ ÙŠØ¬Ø¨ Ø§Ù„Ø­Ø°Ø± Ù…Ù†Ù‡Ø§ØŸ

## 5ï¸âƒ£ Ø§Ù„Ø®Ø·Ø© Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© ÙˆØ§Ù„ØªÙˆØµÙŠØ§Øª
- **Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø¹Ø§Ø¬Ù„Ø© (24 Ø³Ø§Ø¹Ø©)**: Ù…Ø§Ø°Ø§ ÙŠØ¬Ø¨ ÙØ¹Ù„Ù‡ ÙÙˆØ±Ø§Ù‹ØŸ
- **Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ù‚ØµÙŠØ±Ø© Ø§Ù„Ù…Ø¯Ù‰ (Ø£Ø³Ø¨ÙˆØ¹)**: Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø®Ù„Ø§Ù„ Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ Ø§Ù„Ù‚Ø§Ø¯Ù…ØŸ
- **Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ù…ØªÙˆØ³Ø·Ø© Ø§Ù„Ù…Ø¯Ù‰ (Ø´Ù‡Ø±)**: Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ø´Ù‡Ø±ÙŠØ©ØŸ
- **Ù†ØµØ§Ø¦Ø­ ØªÙØ§ÙˆØ¶ÙŠØ©**: ÙƒÙŠÙ ÙŠÙ…ÙƒÙ† Ø­Ù„ Ø§Ù„Ù‚Ø¶ÙŠØ© ÙˆØ¯ÙŠØ§Ù‹ØŸ

## 6ï¸âƒ£ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©
- **Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ø§Ù„Ø£ÙØ¶Ù„**: Ù…Ø§ Ù‡Ùˆ Ø£ÙØ¶Ù„ Ù†ØªÙŠØ¬Ø© Ù…Ù…ÙƒÙ†Ø©ØŸ
- **Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹**: Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø£ÙƒØ«Ø± Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ØŸ
- **Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ø§Ù„Ø£Ø³ÙˆØ£**: Ù…Ø§ Ù‡Ùˆ Ø£Ø³ÙˆØ£ Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ù…Ø­ØªÙ…Ù„ØŸ
- **ØªÙˆØµÙŠØ© Ù†Ù‡Ø§Ø¦ÙŠØ©**: Ù…Ø§ Ù‡ÙŠ Ø§Ù„ØªÙˆØµÙŠØ© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ù‚Ø¶ÙŠØ©ØŸ

**Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù…Ù‡Ù…Ø©:**
- Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ ÙˆØ§Ù„Ù…ØµØ·Ù„Ø­Ø§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø©
- ÙƒÙ† Ù…Ø­Ø¯Ø¯Ø§Ù‹ ÙˆÙˆØ§Ø¶Ø­Ø§Ù‹ ÙÙŠ Ø§Ù„ØªÙˆØµÙŠØ§Øª
- Ø§Ø°ÙƒØ± Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© ÙƒÙ„Ù…Ø§ Ø£Ù…ÙƒÙ†
- Ù‚Ø¯Ù… ØªØ­Ù„ÙŠÙ„Ø§Ù‹ Ù…ÙˆØ¶ÙˆØ¹ÙŠØ§Ù‹ ÙˆÙ…Ù‡Ù†ÙŠØ§Ù‹

**Ø£Ø¹Ø¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¨ØµÙŠØºØ© JSON Ù…Ù†Ø¸Ù…Ø© Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø´ÙƒÙ„:**

```json
{{
  "classification": {{
    "case_type": "Ù†ÙˆØ¹ Ø§Ù„Ù‚Ø¶ÙŠØ©",
    "complexity": "Ø§Ù„Ø¯Ø±Ø¬Ø©",
    "confidence": 85,
    "parties": ["Ø§Ù„Ù…Ø¯Ø¹ÙŠ", "Ø§Ù„Ù…Ø¯Ø¹Ù‰ Ø¹Ù„ÙŠÙ‡"]
  }},
  "legal_analysis": {{
    "facts": "Ø§Ù„ÙˆÙ‚Ø§Ø¦Ø¹ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©",
    "rights_obligations": "Ø§Ù„Ø­Ù‚ÙˆÙ‚ ÙˆØ§Ù„Ø§Ù„ØªØ²Ø§Ù…Ø§Øª",
    "evidence": ["Ø¯Ù„ÙŠÙ„ 1", "Ø¯Ù„ÙŠÙ„ 2"],
    "required_procedures": ["Ø¥Ø¬Ø±Ø§Ø¡ 1", "Ø¥Ø¬Ø±Ø§Ø¡ 2"]
  }},
  "applicable_laws": [
    {{
      "law_name": "Ø§Ø³Ù… Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†",
      "article_numbers": ["Ø§Ù„Ù…Ø§Ø¯Ø© 1", "Ø§Ù„Ù…Ø§Ø¯Ø© 2"],
      "applicability": "Ø´Ø±Ø­ Ø§Ù„Ø§Ù†Ø·Ø¨Ø§Ù‚",
      "conditions": "Ø§Ù„Ø´Ø±ÙˆØ· ÙˆØ§Ù„Ø£Ø­ÙƒØ§Ù…"
    }}
  ],
  "gaps_opportunities": {{
    "procedural_gaps": ["Ø«ØºØ±Ø© 1", "Ø«ØºØ±Ø© 2"],
    "opponent_weaknesses": ["Ø¶Ø¹Ù 1", "Ø¶Ø¹Ù 2"],
    "opportunities": ["ÙØ±ØµØ© 1", "ÙØ±ØµØ© 2"],
    "risks": ["Ø®Ø·Ø± 1", "Ø®Ø·Ø± 2"]
  }},
  "strategic_plan": {{
    "urgent_24h": ["Ø¥Ø¬Ø±Ø§Ø¡ 1", "Ø¥Ø¬Ø±Ø§Ø¡ 2"],
    "short_term_week": ["Ø®Ø·ÙˆØ© 1", "Ø®Ø·ÙˆØ© 2"],
    "medium_term_month": ["Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© 1", "Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© 2"],
    "negotiation_tips": ["Ù†ØµÙŠØ­Ø© 1", "Ù†ØµÙŠØ­Ø© 2"]
  }},
  "outcome_assessment": {{
    "best_case": "Ø£ÙØ¶Ù„ Ù†ØªÙŠØ¬Ø©",
    "expected_case": "Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©",
    "worst_case": "Ø£Ø³ÙˆØ£ Ù†ØªÙŠØ¬Ø©",
    "recommendation": "Ø§Ù„ØªÙˆØµÙŠØ© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©"
  }}
}}
```
"""
        return prompt
    
    async def comprehensive_legal_analysis(self, case_text: str) -> Dict[str, Any]:
        """
        ÙŠÙ‚ÙˆÙ… Ø¨ØªØ­Ù„ÙŠÙ„ Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø´Ø§Ù…Ù„ Ù„Ù„Ù‚Ø¶ÙŠØ© Ø§Ù„Ù…ÙØ¯Ø®Ù„Ø©.
        
        Args:
            case_text: Ù†Øµ Ø§Ù„Ù‚Ø¶ÙŠØ© Ù„Ù„ØªØ­Ù„ÙŠÙ„
            
        Returns:
            ØªØ­Ù„ÙŠÙ„ Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø´Ø§Ù…Ù„ Ø¨ØµÙŠØºØ© dict
        """
        if not self.enabled:
            logger.error("âŒ Gemini is not enabled. Cannot perform analysis.")
            return {
                "success": False,
                "error": "Gemini AI is not configured. Please set GOOGLE_AI_API_KEY.",
                "analysis": None
            }
        
        try:
            logger.info(f"ğŸ” Starting comprehensive legal analysis for case: '{case_text[:100]}...'")
            
            # Create prompt
            prompt = self._create_comprehensive_prompt(case_text)
            
            # Generate response
            response = self.model.generate_content(
                prompt,
                generation_config=self.generation_config,
                safety_settings=self.safety_settings
            )
            
            # Extract text
            analysis_text = response.text
            
            # Try to parse JSON from response
            try:
                # Find JSON in response
                json_start = analysis_text.find('{')
                json_end = analysis_text.rfind('}') + 1
                
                if json_start != -1 and json_end > json_start:
                    json_str = analysis_text[json_start:json_end]
                    analysis_data = json.loads(json_str)
                else:
                    # If no JSON found, create structured response from text
                    analysis_data = {
                        "raw_analysis": analysis_text,
                        "parsed": False
                    }
                    logger.warning("âš ï¸ Could not parse JSON from Gemini response")
                
            except json.JSONDecodeError as e:
                logger.warning(f"âš ï¸ JSON parsing failed: {str(e)}")
                analysis_data = {
                    "raw_analysis": analysis_text,
                    "parsed": False
                }
            
            # Add metadata
            result = {
                "success": True,
                "timestamp": datetime.utcnow().isoformat(),
                "case_text": case_text,
                "analysis": analysis_data,
                "model": "gemini-pro",
                "tokens_used": len(case_text.split()) + len(analysis_text.split())
            }
            
            logger.info(f"âœ… Analysis completed successfully")
            return result
            
        except Exception as e:
            logger.error(f"âŒ Failed to analyze case with Gemini: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "analysis": None
            }
    
    async def quick_case_classification(self, case_text: str) -> Dict[str, Any]:
        """
        ØªØµÙ†ÙŠÙ Ø³Ø±ÙŠØ¹ Ù„Ù„Ù‚Ø¶ÙŠØ© (Ø£Ø®Ù ÙˆØ£Ø³Ø±Ø¹ Ù…Ù† Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„).
        
        Args:
            case_text: Ù†Øµ Ø§Ù„Ù‚Ø¶ÙŠØ©
            
        Returns:
            ØªØµÙ†ÙŠÙ Ø§Ù„Ù‚Ø¶ÙŠØ©
        """
        if not self.enabled:
            return {"success": False, "error": "Gemini not enabled"}
        
        try:
            prompt = f"""Ø£Ù†Øª Ø®Ø¨ÙŠØ± Ù‚Ø§Ù†ÙˆÙ†ÙŠ. ØµÙ†Ù Ù‡Ø°Ù‡ Ø§Ù„Ù‚Ø¶ÙŠØ© Ø¨Ø¥ÙŠØ¬Ø§Ø²:

"{case_text}"

Ø£Ø¹Ø¯ JSON ÙÙ‚Ø·:
{{
  "case_type": "Ø§Ù„Ù†ÙˆØ¹ (Ù…Ø¯Ù†ÙŠ/Ø¬Ù†Ø§Ø¦ÙŠ/Ø¹Ù…Ù„/ØªØ¬Ø§Ø±ÙŠ/Ø¥Ø¯Ø§Ø±ÙŠ)",
  "complexity": "Ø§Ù„Ø¯Ø±Ø¬Ø© (Ø¨Ø³ÙŠØ·Ø©/Ù…ØªÙˆØ³Ø·Ø©/Ù…Ø¹Ù‚Ø¯Ø©)",
  "confidence": 85,
  "key_issue": "Ø§Ù„Ù‚Ø¶ÙŠØ© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ÙÙŠ Ø¬Ù…Ù„Ø© ÙˆØ§Ø­Ø¯Ø©"
}}"""
            
            response = self.model.generate_content(prompt)
            
            # Parse JSON
            text = response.text
            json_start = text.find('{')
            json_end = text.rfind('}') + 1
            
            if json_start != -1 and json_end > json_start:
                classification = json.loads(text[json_start:json_end])
                return {"success": True, "classification": classification}
            
            return {"success": False, "error": "Could not parse classification"}
            
        except Exception as e:
            logger.error(f"âŒ Classification failed: {str(e)}")
            return {"success": False, "error": str(e)}
    
    async def extract_legal_entities(self, case_text: str) -> Dict[str, Any]:
        """
        Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ù…Ù† Ø§Ù„Ù†Øµ (Ø£Ø³Ù…Ø§Ø¡ØŒ ØªÙˆØ§Ø±ÙŠØ®ØŒ Ù…Ø¨Ø§Ù„ØºØŒ Ø¥Ù„Ø®).
        
        Args:
            case_text: Ù†Øµ Ø§Ù„Ù‚Ø¶ÙŠØ©
            
        Returns:
            Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©
        """
        if not self.enabled:
            return {"success": False, "error": "Gemini not enabled"}
        
        try:
            prompt = f"""Ø§Ø³ØªØ®Ø±Ø¬ Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ù…Ù† Ù‡Ø°Ø§ Ø§Ù„Ù†Øµ:

"{case_text}"

Ø£Ø¹Ø¯ JSON ÙÙ‚Ø·:
{{
  "parties": ["Ø§Ø³Ù… 1", "Ø§Ø³Ù… 2"],
  "dates": ["ØªØ§Ø±ÙŠØ® 1", "ØªØ§Ø±ÙŠØ® 2"],
  "amounts": ["Ù…Ø¨Ù„Øº 1", "Ù…Ø¨Ù„Øº 2"],
  "locations": ["Ù…ÙƒØ§Ù† 1", "Ù…ÙƒØ§Ù† 2"],
  "documents": ["Ù…Ø³ØªÙ†Ø¯ 1", "Ù…Ø³ØªÙ†Ø¯ 2"],
  "laws_mentioned": ["Ù‚Ø§Ù†ÙˆÙ† 1", "Ù‚Ø§Ù†ÙˆÙ† 2"]
}}"""
            
            response = self.model.generate_content(prompt)
            text = response.text
            
            json_start = text.find('{')
            json_end = text.rfind('}') + 1
            
            if json_start != -1 and json_end > json_start:
                entities = json.loads(text[json_start:json_end])
                return {"success": True, "entities": entities}
            
            return {"success": False, "error": "Could not parse entities"}
            
        except Exception as e:
            logger.error(f"âŒ Entity extraction failed: {str(e)}")
            return {"success": False, "error": str(e)}
    
    async def generate_legal_strategy(self, case_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """
        ØªÙˆÙ„ÙŠØ¯ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ù…ÙØµÙ„Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„.
        
        Args:
            case_analysis: Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø§Ø¨Ù‚ Ù„Ù„Ù‚Ø¶ÙŠØ©
            
        Returns:
            Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©
        """
        if not self.enabled:
            return {"success": False, "error": "Gemini not enabled"}
        
        try:
            prompt = f"""Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù‡Ø°Ø§ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ:

{json.dumps(case_analysis, ensure_ascii=False, indent=2)}

Ø£Ø¹Ø¯ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© ØªÙØµÙŠÙ„ÙŠØ© ÙƒÙ€ JSON:
{{
  "immediate_actions": ["ÙØ¹Ù„ 1", "ÙØ¹Ù„ 2", "ÙØ¹Ù„ 3"],
  "documents_needed": ["Ù…Ø³ØªÙ†Ø¯ 1", "Ù…Ø³ØªÙ†Ø¯ 2"],
  "witnesses_to_contact": ["Ø´Ø§Ù‡Ø¯ 1", "Ø´Ø§Ù‡Ø¯ 2"],
  "legal_arguments": ["Ø­Ø¬Ø© 1", "Ø­Ø¬Ø© 2"],
  "negotiation_strategy": "Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„ØªÙØ§ÙˆØ¶ÙŠØ©",
  "litigation_strategy": "Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„ØªØ±Ø§ÙØ¹",
  "settlement_options": ["Ø®ÙŠØ§Ø± 1", "Ø®ÙŠØ§Ø± 2"],
  "estimated_timeline": "Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø²Ù…Ù†ÙŠ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹",
  "estimated_costs": "Ø§Ù„ØªÙƒØ§Ù„ÙŠÙ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©",
  "success_probability": 75
}}"""
            
            response = self.model.generate_content(prompt)
            text = response.text
            
            json_start = text.find('{')
            json_end = text.rfind('}') + 1
            
            if json_start != -1 and json_end > json_start:
                strategy = json.loads(text[json_start:json_end])
                return {"success": True, "strategy": strategy}
            
            return {"success": False, "error": "Could not parse strategy"}
            
        except Exception as e:
            logger.error(f"âŒ Strategy generation failed: {str(e)}")
            return {"success": False, "error": str(e)}
    
    async def analyze_with_custom_prompt(self, custom_prompt: str) -> Dict[str, Any]:
        """
        ØªØ­Ù„ÙŠÙ„ Ù…Ø®ØµØµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… prompt Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù….
        
        Args:
            custom_prompt: Prompt Ù…Ø®ØµØµ
            
        Returns:
            Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„
        """
        if not self.enabled:
            return {"success": False, "error": "Gemini not enabled"}
        
        try:
            response = self.model.generate_content(
                custom_prompt,
                generation_config=self.generation_config,
                safety_settings=self.safety_settings
            )
            
            return {
                "success": True,
                "response": response.text,
                "timestamp": datetime.utcnow().isoformat()
            }
            
        except Exception as e:
            logger.error(f"âŒ Custom analysis failed: {str(e)}")
            return {"success": False, "error": str(e)}
    
    def is_enabled(self) -> bool:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Gemini Ù…ÙØ¹Ù‘Ù„ ÙˆÙŠØ¹Ù…Ù„."""
        return self.enabled
