"""
Legal RAG Service - Ø®Ø¯Ù…Ø© Ø§Ù„Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ù…ÙØ¹Ø²Ø² (Retrieval-Augmented Generation)

This service implements advanced RAG for legal analysis by:
1. Retrieving relevant legal context from knowledge base
2. Analyzing with Gemini using that context
3. Providing the most accurate and grounded legal advice
"""

import logging
import json
from typing import Dict, Any, List, Optional
from datetime import datetime
from sqlalchemy.ext.asyncio import AsyncSession

from .gemini_legal_analyzer import GeminiLegalAnalyzer
from ..search.arabic_legal_search_service import ArabicLegalSearchService

logger = logging.getLogger(__name__)


class LegalRAGService:
    """
    Ù†Ø¸Ø§Ù… RAG Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ - Ø£Ø¹Ù„Ù‰ Ø¯Ù‚Ø© Ù…Ù…ÙƒÙ†Ø©.
    
    RAG Workflow:
    1. **Retrieve**: Get relevant laws, cases, and principles from knowledge base
    2. **Augment**: Enrich Gemini's prompt with this context
    3. **Generate**: Let Gemini analyze with full context
    
    Benefits:
    - Grounded in actual laws and cases
    - Reduces AI hallucinations
    - Provides traceable sources
    - Maximum accuracy
    """
    
    def __init__(self, db: AsyncSession, gemini_api_key: Optional[str] = None):
        """
        Initialize Legal RAG Service.
        
        Args:
            db: Async database session
            gemini_api_key: Optional Gemini API key
        """
        self.db = db
        self.gemini_analyzer = GeminiLegalAnalyzer(api_key=gemini_api_key)
        self.search_service = ArabicLegalSearchService(db, use_faiss=True)  # uses paraphrase-multilingual by default
        
        logger.info("âœ… Legal RAG Service initialized with Arabic BERT")
    
    async def rag_analysis(
        self,
        case_text: str,
        max_laws: int = 5,
        max_cases: int = 3,
        include_principles: bool = True
    ) -> Dict[str, Any]:
        """
        ØªØ­Ù„ÙŠÙ„ RAG ÙƒØ§Ù…Ù„ - ÙŠØ³ØªØ±Ø¬Ø¹ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø«Ù… ÙŠØ­Ù„Ù„ Ù…Ø¹ Gemini.
        
        Args:
            case_text: Ù†Øµ Ø§Ù„Ù‚Ø¶ÙŠØ©
            max_laws: Ø¹Ø¯Ø¯ Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ù…Ø³ØªØ±Ø¬Ø¹Ø© (Ø§ÙØªØ±Ø§Ø¶ÙŠ 5)
            max_cases: Ø¹Ø¯Ø¯ Ø§Ù„Ù‚Ø¶Ø§ÙŠØ§ Ø§Ù„Ù…Ø´Ø§Ø¨Ù‡Ø© (Ø§ÙØªØ±Ø§Ø¶ÙŠ 3)
            include_principles: ØªØ¶Ù…ÙŠÙ† Ø§Ù„Ù…Ø¨Ø§Ø¯Ø¦ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©
            
        Returns:
            ØªØ­Ù„ÙŠÙ„ Ù…ÙØ¹Ø²Ø² Ø¨Ø§Ù„Ø³ÙŠØ§Ù‚
        """
        try:
            logger.info(f"ğŸ” Starting RAG analysis for case: '{case_text[:100]}...'")
            start_time = datetime.utcnow()
            
            # Step 1: Retrieve relevant context
            logger.info("ğŸ“š Step 1: Retrieving relevant context from knowledge base...")
            context = await self.retrieve_relevant_context(
                case_text,
                max_laws=max_laws,
                max_cases=max_cases,
                include_principles=include_principles
            )
            
            # Step 2: Analyze with context using Gemini
            logger.info("ğŸ¤– Step 2: Analyzing with Gemini using retrieved context...")
            analysis = await self.analyze_with_context(case_text, context)
            
            # Step 3: Post-process and enhance
            logger.info("âœ¨ Step 3: Enhancing results...")
            final_result = self._enhance_analysis(analysis, context)
            
            # Calculate processing time
            end_time = datetime.utcnow()
            processing_time = (end_time - start_time).total_seconds()
            
            final_result.update({
                "processing_time_seconds": processing_time,
                "timestamp": end_time.isoformat(),
                "analysis_type": "rag"
            })
            
            logger.info(f"âœ… RAG analysis completed in {processing_time:.2f} seconds")
            
            return final_result
            
        except Exception as e:
            logger.error(f"âŒ RAG analysis failed: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }
    
    async def retrieve_relevant_context(
        self,
        case_text: str,
        max_laws: int = 5,
        max_cases: int = 3,
        include_principles: bool = True
    ) -> Dict[str, Any]:
        """
        Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø£ÙƒØ«Ø± ØµÙ„Ø© Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©.
        
        Args:
            case_text: Ù†Øµ Ø§Ù„Ù‚Ø¶ÙŠØ©
            max_laws: Ø¹Ø¯Ø¯ Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ù…Ø³ØªØ±Ø¬Ø¹Ø©
            max_cases: Ø¹Ø¯Ø¯ Ø§Ù„Ù‚Ø¶Ø§ÙŠØ§ Ø§Ù„Ù…Ø´Ø§Ø¨Ù‡Ø©
            include_principles: ØªØ¶Ù…ÙŠÙ† Ø§Ù„Ù…Ø¨Ø§Ø¯Ø¦ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©
            
        Returns:
            Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…ÙØ³ØªØ±Ø¬Ø¹
        """
        try:
            context = {
                "similar_laws": [],
                "similar_cases": [],
                "legal_principles": [],
                "procedural_rules": [],
                "sources_count": 0
            }
            
            # Retrieve similar laws
            logger.info(f"ğŸ” Searching for {max_laws} similar laws...")
            similar_laws = await self.search_service.find_similar_laws(
                query=case_text,
                top_k=max_laws,
                threshold=0.65
            )
            
            context['similar_laws'] = [
                {
                    "content": law['content'],
                    "similarity": law['similarity'],
                    "source": law.get('law_metadata', {}).get('law_name', 'Unknown'),
                    "article": law.get('article_metadata', {}).get('article_number', ''),
                    "verified": law.get('verified', False)
                }
                for law in similar_laws
            ]
            
            # Retrieve similar cases
            logger.info(f"ğŸ” Searching for {max_cases} similar cases...")
            similar_cases = await self.search_service.find_similar_cases(
                query=case_text,
                top_k=max_cases,
                threshold=0.70
            )
            
            context['similar_cases'] = [
                {
                    "content": case['content'],
                    "similarity": case['similarity'],
                    "case_number": case.get('case_metadata', {}).get('case_number', ''),
                    "court": case.get('case_metadata', {}).get('court_name', ''),
                    "decision_date": case.get('case_metadata', {}).get('decision_date', '')
                }
                for case in similar_cases
            ]
            
            # Extract legal principles (if requested)
            if include_principles:
                logger.info("ğŸ“– Extracting legal principles...")
                context['legal_principles'] = await self._extract_legal_principles(
                    context['similar_laws'],
                    context['similar_cases']
                )
            
            # Extract procedural rules
            logger.info("âš–ï¸ Extracting procedural rules...")
            context['procedural_rules'] = await self._extract_procedural_rules(
                context['similar_laws']
            )
            
            # Count sources
            context['sources_count'] = len(context['similar_laws']) + len(context['similar_cases'])
            
            logger.info(f"âœ… Retrieved {context['sources_count']} sources from knowledge base")
            
            return context
            
        except Exception as e:
            logger.error(f"âŒ Context retrieval failed: {str(e)}")
            return {
                "error": str(e),
                "similar_laws": [],
                "similar_cases": [],
                "sources_count": 0
            }
    
    async def _extract_legal_principles(
        self,
        laws: List[Dict],
        cases: List[Dict]
    ) -> List[str]:
        """
        Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø¨Ø§Ø¯Ø¦ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ù…Ù† Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† ÙˆØ§Ù„Ù‚Ø¶Ø§ÙŠØ§.
        
        Args:
            laws: Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ†
            cases: Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù‚Ø¶Ø§ÙŠØ§
            
        Returns:
            Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ø¨Ø§Ø¯Ø¦ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©
        """
        try:
            principles = []
            
            # Extract from high-similarity verified laws
            for law in laws:
                if law.get('verified') and law.get('similarity', 0) > 0.8:
                    # Extract key phrases that look like principles
                    content = law.get('content', '')
                    if any(keyword in content for keyword in ['ÙŠØ¬Ø¨', 'Ù„Ø§ ÙŠØ¬ÙˆØ²', 'ÙŠØ­Ù‚', 'ÙŠÙ„ØªØ²Ù…']):
                        principles.append(content[:200] + "...")
            
            # Extract from cases (precedents)
            for case in cases:
                if case.get('similarity', 0) > 0.85:
                    content = case.get('content', '')
                    if any(keyword in content for keyword in ['Ø§Ù„Ù…Ø¨Ø¯Ø£', 'Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø©', 'Ø­ÙƒÙ…Øª Ø§Ù„Ù…Ø­ÙƒÙ…Ø©']):
                        principles.append(f"Ø³Ø§Ø¨Ù‚Ø© Ù‚Ø¶Ø§Ø¦ÙŠØ©: {content[:150]}...")
            
            return principles[:5]  # Top 5 principles
            
        except Exception as e:
            logger.error(f"âŒ Failed to extract principles: {str(e)}")
            return []
    
    async def _extract_procedural_rules(self, laws: List[Dict]) -> List[str]:
        """
        Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¦ÙŠØ© Ù…Ù† Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ†.
        
        Args:
            laws: Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ†
            
        Returns:
            Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¦ÙŠØ©
        """
        try:
            rules = []
            
            for law in laws:
                content = law.get('content', '')
                # Look for procedural keywords
                if any(keyword in content for keyword in ['Ø¥Ø¬Ø±Ø§Ø¡', 'Ù…Ø¯Ø©', 'Ù…ÙŠØ¹Ø§Ø¯', 'ØªÙ‚Ø¯ÙŠÙ…', 'Ù…Ø­ÙƒÙ…Ø©']):
                    rules.append(content[:150] + "...")
            
            return rules[:3]  # Top 3 rules
            
        except Exception as e:
            logger.error(f"âŒ Failed to extract rules: {str(e)}")
            return []
    
    async def analyze_with_context(
        self,
        case_text: str,
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø¶ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini Ù…Ø¹ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…ÙØ³ØªØ±Ø¬Ø¹.
        
        Args:
            case_text: Ù†Øµ Ø§Ù„Ù‚Ø¶ÙŠØ©
            context: Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…ÙØ³ØªØ±Ø¬Ø¹
            
        Returns:
            Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙØ¹Ø²Ø²
        """
        try:
            # Build enhanced prompt with context
            prompt = self._build_rag_prompt(case_text, context)
            
            # Get analysis from Gemini
            result = await self.gemini_analyzer.analyze_with_custom_prompt(prompt)
            
            if not result.get('success'):
                logger.error(f"âŒ Gemini analysis failed: {result.get('error')}")
                return result
            
            # Try to parse as JSON
            response_text = result.get('response', '')
            
            try:
                json_start = response_text.find('{')
                json_end = response_text.rfind('}') + 1
                
                if json_start != -1 and json_end > json_start:
                    analysis_json = json.loads(response_text[json_start:json_end])
                else:
                    analysis_json = {"raw_response": response_text}
                
            except json.JSONDecodeError:
                analysis_json = {"raw_response": response_text}
            
            return {
                "success": True,
                "analysis": analysis_json,
                "context_used": {
                    "laws_count": len(context.get('similar_laws', [])),
                    "cases_count": len(context.get('similar_cases', [])),
                    "principles_count": len(context.get('legal_principles', []))
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ Analysis with context failed: {str(e)}")
            return {"success": False, "error": str(e)}
    
    def _build_rag_prompt(self, case_text: str, context: Dict[str, Any]) -> str:
        """
        Ø¨Ù†Ø§Ø¡ prompt Ù…ÙØ¹Ø²Ø² Ø¨Ø§Ù„Ø³ÙŠØ§Ù‚ Ù„Ù€ Gemini.
        
        Args:
            case_text: Ù†Øµ Ø§Ù„Ù‚Ø¶ÙŠØ©
            context: Ø§Ù„Ø³ÙŠØ§Ù‚
            
        Returns:
            Prompt ÙƒØ§Ù…Ù„
        """
        prompt = f"""Ø£Ù†Øª Ù…Ø­Ø§Ù…ÙŠ Ø®Ø¨ÙŠØ± ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ Ù…Ø¹ Ø®Ø¨Ø±Ø© 20 Ø¹Ø§Ù…Ø§Ù‹.

**ğŸ“‹ Ø§Ù„Ù‚Ø¶ÙŠØ© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ØªØ­Ù„ÙŠÙ„Ù‡Ø§:**
"{case_text}"

**ğŸ“š Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø°Ø§Øª ØµÙ„Ø© Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©:**

### ğŸ“œ Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† ÙˆØ§Ù„Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ù…Ø´Ø§Ø¨Ù‡Ø© ({len(context.get('similar_laws', []))} Ù†ØªÙŠØ¬Ø©):
"""
        
        # Add similar laws
        for i, law in enumerate(context.get('similar_laws', [])[:5], 1):
            prompt += f"\n**{i}. {law.get('source', 'Unknown')}** (ØªØ´Ø§Ø¨Ù‡: {law.get('similarity', 0):.0%})\n"
            prompt += f"   Ø§Ù„Ù…Ø§Ø¯Ø©: {law.get('article', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}\n"
            prompt += f"   Ø§Ù„Ù†Øµ: {law.get('content', '')[:300]}...\n"
            if law.get('verified'):
                prompt += f"   âœ… Ù…Ø­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¥Ø¯Ø§Ø±Ø©\n"
        
        # Add similar cases
        if context.get('similar_cases'):
            prompt += f"\n### âš–ï¸ Ø³ÙˆØ§Ø¨Ù‚ Ù‚Ø¶Ø§Ø¦ÙŠØ© Ù…Ø´Ø§Ø¨Ù‡Ø© ({len(context['similar_cases'])} Ù†ØªÙŠØ¬Ø©):\n"
            for i, case in enumerate(context['similar_cases'][:3], 1):
                prompt += f"\n**{i}. Ø§Ù„Ù‚Ø¶ÙŠØ© Ø±Ù‚Ù… {case.get('case_number', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}** (ØªØ´Ø§Ø¨Ù‡: {case.get('similarity', 0):.0%})\n"
                prompt += f"   Ø§Ù„Ù…Ø­ÙƒÙ…Ø©: {case.get('court', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}\n"
                prompt += f"   Ø§Ù„ØªØ§Ø±ÙŠØ®: {case.get('decision_date', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}\n"
                prompt += f"   Ø§Ù„Ù…Ù„Ø®Øµ: {case.get('content', '')[:250]}...\n"
        
        # Add legal principles
        if context.get('legal_principles'):
            prompt += f"\n### ğŸ“– Ø§Ù„Ù…Ø¨Ø§Ø¯Ø¦ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©:\n"
            for i, principle in enumerate(context['legal_principles'], 1):
                prompt += f"{i}. {principle}\n"
        
        # Add procedural rules
        if context.get('procedural_rules'):
            prompt += f"\n### âš–ï¸ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¦ÙŠØ© Ø§Ù„Ù…Ù‡Ù…Ø©:\n"
            for i, rule in enumerate(context['procedural_rules'], 1):
                prompt += f"{i}. {rule}\n"
        
        prompt += f"""

**ğŸ¯ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ù…Ù†Ùƒ:**

Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø£Ø¹Ù„Ø§Ù‡ Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ù„ØªÙ‚Ø¯ÙŠÙ… ØªØ­Ù„ÙŠÙ„ Ø¯Ù‚ÙŠÙ‚ ÙˆÙ…ÙØ³ØªÙ†Ø¯ Ø¥Ù„Ù‰ Ù…ØµØ§Ø¯Ø± Ø­Ù‚ÙŠÙ‚ÙŠØ©.

Ù‚Ø¯Ù… ØªØ­Ù„ÙŠÙ„Ø§Ù‹ Ù‚Ø§Ù†ÙˆÙ†ÙŠØ§Ù‹ Ø´Ø§Ù…Ù„Ø§Ù‹ ÙŠØªØ¶Ù…Ù†:

1. **Ø§Ù„ØªØµÙ†ÙŠÙ ÙˆØ§Ù„ØªÙ‚ÙŠÙŠÙ…**:
   - Ù†ÙˆØ¹ Ø§Ù„Ù‚Ø¶ÙŠØ© Ø¨Ø¯Ù‚Ø©
   - Ø¯Ø±Ø¬Ø© Ø§Ù„ØªØ¹Ù‚ÙŠØ¯
   - Ø§Ù„Ø£Ø·Ø±Ø§Ù Ø§Ù„Ù…Ø¹Ù†ÙŠØ©

2. **Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø§Ù„Ù…ÙØ³ØªÙ†Ø¯**:
   - Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† ÙˆØ§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù…Ø°ÙƒÙˆØ±Ø© Ø£Ø¹Ù„Ø§Ù‡
   - Ø§Ø´Ø±Ø­ ÙƒÙŠÙÙŠØ© Ø§Ù†Ø·Ø¨Ø§Ù‚Ù‡Ø§ Ø¹Ù„Ù‰ Ù‡Ø°Ù‡ Ø§Ù„Ù‚Ø¶ÙŠØ©
   - Ø§Ø³ØªØ´Ù‡Ø¯ Ø¨Ø§Ù„Ø³ÙˆØ§Ø¨Ù‚ Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠØ© Ø§Ù„Ù…Ø´Ø§Ø¨Ù‡Ø©

3. **Ø§Ù„Ø­Ù‚ÙˆÙ‚ ÙˆØ§Ù„Ø§Ù„ØªØ²Ø§Ù…Ø§Øª**:
   - Ø­Ù‚ÙˆÙ‚ ÙƒÙ„ Ø·Ø±Ù Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ù…Ø°ÙƒÙˆØ±Ø©
   - Ø§Ù„Ø§Ù„ØªØ²Ø§Ù…Ø§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©

4. **Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ù…ÙˆØµÙ‰ Ø¨Ù‡Ø§**:
   - Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ø¹Ø§Ø¬Ù„Ø©
   - Ø§Ù„Ø®Ø·ÙˆØ§Øª Ù‚ØµÙŠØ±Ø© ÙˆÙ…ØªÙˆØ³Ø·Ø© Ø§Ù„Ù…Ø¯Ù‰
   - Ù†ØµØ§Ø¦Ø­ ØªÙØ§ÙˆØ¶ÙŠØ©

5. **ØªÙ‚ÙŠÙŠÙ… Ø§Ù„ÙØ±Øµ ÙˆØ§Ù„Ù…Ø®Ø§Ø·Ø±**:
   - Ù†Ù‚Ø§Ø· Ø§Ù„Ù‚ÙˆØ© Ø§Ø³ØªÙ†Ø§Ø¯Ø§Ù‹ Ù„Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† ÙˆØ§Ù„Ø³ÙˆØ§Ø¨Ù‚
   - Ø§Ù„Ù…Ø®Ø§Ø·Ø± Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©
   - Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ø§Ù„Ù†Ø¬Ø§Ø­

**âš ï¸ Ù…Ù‡Ù… Ø¬Ø¯Ø§Ù‹:**
- Ø§Ø³ØªÙ†Ø¯ ÙÙ‚Ø· Ù„Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø°ÙƒÙˆØ±Ø© Ø£Ø¹Ù„Ø§Ù‡ Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©
- Ø§Ø°ÙƒØ± Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…ÙˆØ§Ø¯ ÙˆØ§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† Ø¨Ø¯Ù‚Ø© ÙƒÙ…Ø§ ÙˆØ±Ø¯Øª
- Ø§Ø³ØªØ´Ù‡Ø¯ Ø¨Ø§Ù„Ø³ÙˆØ§Ø¨Ù‚ Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠØ© Ø§Ù„Ù…Ø´Ø§Ø¨Ù‡Ø©
- Ø¥Ø°Ø§ Ù„Ù… ØªØ¬Ø¯ Ù…Ø¹Ù„ÙˆÙ…Ø© ÙƒØ§ÙÙŠØ©ØŒ ÙˆØ¶Ø­ Ø°Ù„Ùƒ

Ø£Ø¹Ø¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¨ØµÙŠØºØ© JSON Ù…Ù†Ø¸Ù…Ø©:

```json
{{
  "classification": {{
    "case_type": "Ø§Ù„Ù†ÙˆØ¹",
    "complexity": "Ø§Ù„Ø¯Ø±Ø¬Ø©",
    "confidence": 90,
    "parties": ["Ø·Ø±Ù 1", "Ø·Ø±Ù 2"]
  }},
  "legal_analysis": {{
    "applicable_laws": [
      {{
        "law_name": "Ø§Ø³Ù… Ø§Ù„Ù‚Ø§Ù†ÙˆÙ† Ù…Ù† Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø£Ø¹Ù„Ø§Ù‡",
        "article_number": "Ø±Ù‚Ù… Ø§Ù„Ù…Ø§Ø¯Ø© Ø¨Ø§Ù„Ø¶Ø¨Ø·",
        "relevance": "Ø´Ø±Ø­ Ø§Ù„Ø§Ù†Ø·Ø¨Ø§Ù‚"
      }}
    ],
    "case_precedents": [
      {{
        "case_number": "Ø±Ù‚Ù… Ø§Ù„Ù‚Ø¶ÙŠØ© Ù…Ù† Ø§Ù„Ù…ØµØ§Ø¯Ø±",
        "relevance": "ÙˆØ¬Ù‡ Ø§Ù„Ø´Ø¨Ù‡"
      }}
    ],
    "rights_obligations": "Ø§Ù„Ø­Ù‚ÙˆÙ‚ ÙˆØ§Ù„Ø§Ù„ØªØ²Ø§Ù…Ø§Øª Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø© Ù„Ù„Ù‚ÙˆØ§Ù†ÙŠÙ†"
  }},
  "strategy": {{
    "immediate_actions": ["Ø¥Ø¬Ø±Ø§Ø¡ 1", "Ø¥Ø¬Ø±Ø§Ø¡ 2"],
    "short_term": ["Ø®Ø·ÙˆØ© 1", "Ø®Ø·ÙˆØ© 2"],
    "medium_term": ["Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© 1", "Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© 2"],
    "negotiation_tips": ["Ù†ØµÙŠØ­Ø© 1", "Ù†ØµÙŠØ­Ø© 2"]
  }},
  "risk_assessment": {{
    "strengths": ["Ù‚ÙˆØ© 1 Ù…Ø³ØªÙ†Ø¯Ø© Ù„Ù„Ù…ØµØ§Ø¯Ø±", "Ù‚ÙˆØ© 2"],
    "weaknesses": ["Ø¶Ø¹Ù 1", "Ø¶Ø¹Ù 2"],
    "opportunities": ["ÙØ±ØµØ© 1", "ÙØ±ØµØ© 2"],
    "threats": ["ØªÙ‡Ø¯ÙŠØ¯ 1", "ØªÙ‡Ø¯ÙŠØ¯ 2"],
    "success_probability": 75
  }},
  "recommendation": "Ø§Ù„ØªÙˆØµÙŠØ© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ø§Ù„Ù…Ø¨Ù†ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ù…ØµØ§Ø¯Ø±"
}}
```
"""
        
        return prompt
    
    def _enhance_analysis(
        self,
        analysis: Dict[str, Any],
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…ØµØ§Ø¯Ø± ÙˆØ§Ù„Ù…Ø±Ø§Ø¬Ø¹.
        
        Args:
            analysis: Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ù…Ù† Gemini
            context: Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…ÙØ³ØªØ±Ø¬Ø¹
            
        Returns:
            Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙØ­Ø³Ù‘Ù†
        """
        try:
            enhanced = {
                "success": analysis.get('success', False),
                "analysis": analysis.get('analysis', {}),
                "sources": {
                    "laws": context.get('similar_laws', []),
                    "cases": context.get('similar_cases', []),
                    "principles": context.get('legal_principles', []),
                    "procedural_rules": context.get('procedural_rules', [])
                },
                "metadata": {
                    "sources_count": context.get('sources_count', 0),
                    "laws_used": len(context.get('similar_laws', [])),
                    "cases_used": len(context.get('similar_cases', [])),
                    "context_provided": analysis.get('context_used', {})
                },
                "quality_indicators": {
                    "grounded_in_sources": True,
                    "traceable": True,
                    "verified_laws_used": sum(1 for law in context.get('similar_laws', []) if law.get('verified'))
                }
            }
            
            return enhanced
            
        except Exception as e:
            logger.error(f"âŒ Enhancement failed: {str(e)}")
            return analysis
    
    async def answer_legal_question(
        self,
        question: str,
        context_type: str = "both"
    ) -> Dict[str, Any]:
        """
        Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø³Ø¤Ø§Ù„ Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… RAG.
        
        Args:
            question: Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ
            context_type: Ù†ÙˆØ¹ Ø§Ù„Ø³ÙŠØ§Ù‚ ('laws', 'cases', 'both')
            
        Returns:
            Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ù…Ø¹ Ø§Ù„Ù…ØµØ§Ø¯Ø±
        """
        try:
            logger.info(f"â“ Answering question: '{question[:100]}...'")
            
            # Retrieve context based on type
            if context_type in ['laws', 'both']:
                laws = await self.search_service.find_similar_laws(question, top_k=3, threshold=0.7)
            else:
                laws = []
            
            if context_type in ['cases', 'both']:
                cases = await self.search_service.find_similar_cases(question, top_k=2, threshold=0.7)
            else:
                cases = []
            
            # Build prompt
            prompt = f"""Ø£Ø¬Ø¨ Ø¹Ù„Ù‰ Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„ØªØ§Ù„ÙŠØ©:

**Ø§Ù„Ø³Ø¤Ø§Ù„:** {question}

**Ø§Ù„Ù…ØµØ§Ø¯Ø±:**
"""
            
            for i, law in enumerate(laws, 1):
                prompt += f"\n{i}. {law.get('law_metadata', {}).get('law_name', 'Ù‚Ø§Ù†ÙˆÙ†')}: {law['content'][:200]}...\n"
            
            for i, case in enumerate(cases, 1):
                prompt += f"\n{i}. Ù‚Ø¶ÙŠØ© {case.get('case_metadata', {}).get('case_number', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}: {case['content'][:200]}...\n"
            
            prompt += "\n\nØ£Ø¬Ø¨ Ø¨ÙˆØ¶ÙˆØ­ Ù…Ø¹ Ø§Ù„Ø§Ø³ØªØ´Ù‡Ø§Ø¯ Ø¨Ø§Ù„Ù…ØµØ§Ø¯Ø±."
            
            # Get answer from Gemini
            result = await self.gemini_analyzer.analyze_with_custom_prompt(prompt)
            
            return {
                "success": result.get('success', False),
                "question": question,
                "answer": result.get('response', ''),
                "sources": {
                    "laws": laws,
                    "cases": cases
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ Question answering failed: {str(e)}")
            return {"success": False, "error": str(e)}
